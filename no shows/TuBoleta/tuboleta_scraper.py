from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.keys import Keys
import time
import logging
import os
from datetime import datetime
import json
import random
import string
import platform
import subprocess
from bs4 import BeautifulSoup
import pandas as pd
import re
from database_config import get_database_connection

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TuboletaScraper:
    def __init__(self, headless=False):
        """
        Inicializa el scraper de Tuboleta con evasi√≥n avanzada de bots
        
        Args:
            headless (bool): Si True, ejecuta el navegador en modo headless
        """
        self.driver = None
        self.headless = headless
        self.login_url = "https://repsuenoestereo.checkout.tuboleta.com/account/login"
        self.dashboard_url = "https://repsuenoestereo.checkout.tuboleta.com/report/dashboard"
        
        # Lista de credenciales para probar una por una
        self.credentials = [
            {"email": "camila.halfon@daleplay.la", "password": "RelsBbogota1"}
        ]
        self.current_credential_index = 0
        
        # Crear carpeta para descargas
        self.download_folder = "Tuboleta/jsontuboleta"
        self.setup_download_folder()
        
        # Configuraci√≥n de evasi√≥n de bots
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36"
        ]
        
        # Configuraci√≥n de evasi√≥n
        self.evasion_config = {
            "random_delays": True,
            "human_typing": True,
            "mouse_movement": True,
            "scroll_behavior": True,
            "window_resize": True,
            "fingerprint_spoofing": True
        }
        
        logger.info("=== INICIALIZACI√ìN DEL SCRAPER TUBOLETA ===")
        logger.info(f"URL de login: {self.login_url}")
        logger.info(f"URL de dashboard: {self.dashboard_url}")
        logger.info(f"Modo headless: {self.headless}")
        logger.info(f"Carpeta de descargas: {self.download_folder}")
        logger.info("üõ°Ô∏è MODOS DE EVASI√ìN ACTIVADOS:")
        for key, value in self.evasion_config.items():
            logger.info(f"  üõ°Ô∏è {key}: {'‚úÖ' if value else '‚ùå'}")
        
    def setup_download_folder(self):
        """Crea la carpeta para descargas si no existe"""
        try:
            if not os.path.exists(self.download_folder):
                os.makedirs(self.download_folder)
                logger.info(f"Carpeta creada: {self.download_folder}")
            else:
                logger.info(f"Carpeta ya existe: {self.download_folder}")
        except Exception as e:
            logger.error(f"Error creando carpeta de descargas: {str(e)}")
    
    def setup_driver(self):
        """Configura el driver de Chrome con las opciones necesarias"""
        try:
            logger.info("üîß Configurando driver de Chrome...")
            
            chrome_options = Options()
            
            if self.headless:
                chrome_options.add_argument("--headless")
                logger.info("üåê Modo headless activado")
            
            # Opciones b√°sicas para Windows
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--window-size=1920,1080")
            
            # Configurar user agent aleatorio
            user_agent = random.choice(self.user_agents)
            chrome_options.add_argument(f"--user-agent={user_agent}")
            logger.info(f"üé≠ User agent configurado: {user_agent[:50]}...")
            
            # Configurar carpeta de descargas
            chrome_options.add_experimental_option("prefs", {
                "download.default_directory": os.path.abspath(self.download_folder),
                "download.prompt_for_download": False,
                "download.directory_upgrade": True,
                "safebrowsing.enabled": True
            })
            
            # Opciones adicionales para evadir detecci√≥n
            chrome_options.add_argument("--disable-blink-features=AutomationControlled")
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            logger.info("‚öôÔ∏è Opciones de Chrome configuradas")
            
            # Intentar configurar el driver de forma simple
            try:
                logger.info("üîÑ Intentando configuraci√≥n simple del driver...")
                self.driver = webdriver.Chrome(options=chrome_options)
                logger.info("‚úÖ Driver configurado con configuraci√≥n simple")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error con configuraci√≥n simple: {str(e)}")
                logger.info("üîÑ Intentando con webdriver-manager como respaldo...")
                # Intentar con webdriver-manager como respaldo
                service = Service(ChromeDriverManager().install())
                self.driver = webdriver.Chrome(service=service, options=chrome_options)
                logger.info("‚úÖ Driver configurado con webdriver-manager")
            
            # Ejecutar script para ocultar el hecho de que selenium est√° ejecut√°ndose
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            logger.info("üéâ Driver de Chrome configurado exitosamente")
            
            # Aplicar evasi√≥n avanzada despu√©s de configurar el driver
            self.apply_advanced_evasion()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error al configurar el driver: {str(e)}")
            return False
    
    def apply_advanced_evasion(self):
        """Applies advanced evasion techniques to mimic human behavior"""
        try:
            logger.info("üõ°Ô∏è Aplicando t√©cnicas avanzadas de evasi√≥n...")
            # Simulate random scrolling
            self.simulate_scrolling()
            # Simulate random window resizing
            self.simulate_window_resizing()
            logger.info("‚úÖ T√©cnicas de evasi√≥n aplicadas exitosamente")
        except Exception as e:
            logger.error(f"‚ùå Error aplicando t√©cnicas de evasi√≥n: {str(e)}")

    def simulate_mouse_movements(self):
        """Simulates random mouse movements to mimic human behavior"""
        try:
            logger.info("üñ±Ô∏è Simulando movimientos de mouse...")
            actions = ActionChains(self.driver)
            for _ in range(random.randint(2, 5)):
                x_offset = random.randint(-100, 100)
                y_offset = random.randint(-100, 100)
                actions.move_by_offset(x_offset, y_offset).perform()
                time.sleep(random.uniform(0.1, 0.3))
            logger.info("‚úÖ Movimientos de mouse simulados")
        except Exception as e:
            logger.error(f"‚ùå Error simulando movimientos de mouse: {str(e)}")

    def simulate_scrolling(self):
        """Simulates random scrolling to mimic human behavior"""
        try:
            logger.info("üñ±Ô∏è Simulando desplazamiento...")
            for _ in range(random.randint(1, 3)):
                scroll_amount = random.randint(-200, 200)
                self.driver.execute_script(f"window.scrollBy(0, {scroll_amount});")
                time.sleep(random.uniform(0.2, 0.4))
            logger.info("‚úÖ Desplazamiento simulado")
        except Exception as e:
            logger.error(f"‚ùå Error simulando desplazamiento: {str(e)}")

    def simulate_window_resizing(self):
        """Simulates random window resizing to mimic human behavior"""
        try:
            logger.info("üñ•Ô∏è Simulando cambio de tama√±o de ventana...")
            for _ in range(random.randint(1, 2)):
                width = random.randint(1200, 1920)
                height = random.randint(800, 1080)
                self.driver.set_window_size(width, height)
                time.sleep(random.uniform(0.3, 0.7))
            logger.info("‚úÖ Cambio de tama√±o de ventana simulado")
        except Exception as e:
            logger.error(f"‚ùå Error simulando cambio de tama√±o de ventana: {str(e)}")
    
    def navigate_to_login(self):
        """Navega a la p√°gina de login de Tuboleta"""
        try:
            logger.info("üåê Navegando a la p√°gina de login de Tuboleta...")
            logger.info(f"üìç URL: {self.login_url}")
            
            self.driver.get(self.login_url)
            
            # Esperar a que la p√°gina cargue completamente
            logger.info("‚è≥ Esperando a que la p√°gina cargue...")
            WebDriverWait(self.driver, 15).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # Obtener el t√≠tulo de la p√°gina
            page_title = self.driver.title
            logger.info(f"üìÑ T√≠tulo de la p√°gina: {page_title}")
            
            # Obtener la URL actual
            current_url = self.driver.current_url
            logger.info(f"üîó URL actual: {current_url}")
            
            # Verificar si estamos en la p√°gina correcta
            if "tuboleta" in current_url.lower():
                logger.info("‚úÖ P√°gina de Tuboleta cargada exitosamente")
            else:
                logger.warning("‚ö†Ô∏è Posible redirecci√≥n a otra p√°gina")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error navegando a la p√°gina de login: {str(e)}")
            return False
    
    def human_type(self, element, text):
        """Simula escritura humana con pausas aleatorias"""
        try:
            element.clear()
            time.sleep(random.uniform(0.1, 0.3))
            
            for char in text:
                element.send_keys(char)
                time.sleep(random.uniform(0.05, 0.15))  # Pausa entre caracteres
            
            time.sleep(random.uniform(0.2, 0.5))  # Pausa despu√©s de escribir
            
        except Exception as e:
            logger.error(f"‚ùå Error en escritura humana: {str(e)}")
            raise
    
    def get_page_info(self):
        """Obtiene informaci√≥n b√°sica de la p√°gina"""
        try:
            title = self.driver.title
            current_url = self.driver.current_url
            
            logger.info(f"T√≠tulo de la p√°gina: {title}")
            logger.info(f"URL actual: {current_url}")
            
            return {
                'title': title,
                'url': current_url
            }
            
        except Exception as e:
            logger.error(f"Error al obtener informaci√≥n de la p√°gina: {str(e)}")
            return None
    
    def debug_page_elements(self):
        """Debug: Muestra todos los elementos de input en la p√°gina"""
        try:
            logger.info("=== DEBUG: Analizando elementos de la p√°gina ===")
            
            # Buscar todos los inputs
            inputs = self.driver.find_elements(By.TAG_NAME, "input")
            logger.info(f"Total de inputs encontrados: {len(inputs)}")
            
            for i, input_elem in enumerate(inputs):
                try:
                    input_type = input_elem.get_attribute("type")
                    input_name = input_elem.get_attribute("name")
                    input_id = input_elem.get_attribute("id")
                    input_class = input_elem.get_attribute("class")
                    
                    logger.info(f"Input {i+1}: type='{input_type}', name='{input_name}', id='{input_id}', class='{input_class}'")
                except:
                    continue
            
            # Buscar todos los botones
            buttons = self.driver.find_elements(By.TAG_NAME, "button")
            logger.info(f"Total de botones encontrados: {len(buttons)}")
            
            for i, button in enumerate(buttons):
                try:
                    button_text = button.text
                    button_type = button.get_attribute("type")
                    button_class = button.get_attribute("class")
                    
                    logger.info(f"Bot√≥n {i+1}: text='{button_text}', type='{button_type}', class='{button_class}'")
                except:
                    continue
            
            # Buscar todos los forms
            forms = self.driver.find_elements(By.TAG_NAME, "form")
            logger.info(f"Total de formularios encontrados: {len(forms)}")
            
            for i, form_elem in enumerate(forms):
                try:
                    form_action = form_elem.get_attribute("action")
                    form_id = form_elem.get_attribute("id")
                    form_class = form_elem.get_attribute("class")
                    
                    logger.info(f"Form {i+1}: action='{form_action}', id='{form_id}', class='{form_class}'")
                except:
                    continue
            
            logger.info("=== FIN DEBUG ===")
            
        except Exception as e:
            logger.error(f"Error en debug: {str(e)}")
    
    def wait_for_login_form(self):
        """Espera a que cargue el formulario de login"""
        try:
            logger.info("Esperando a que cargue el formulario de login...")
            
            # Esperar m√°s tiempo para que la p√°gina cargue completamente
            time.sleep(5)
            
            # Usar los selectores espec√≠ficos de Tuboleta basados en el HTML proporcionado
            email_field = WebDriverWait(self.driver, 10).until(
                EC.element_to_be_clickable((By.ID, "login"))
            )
            logger.info("Campo de email encontrado con selector: (By.ID, 'login')")
            
            password_field = WebDriverWait(self.driver, 10).until(
                EC.element_to_be_clickable((By.ID, "password"))
            )
            logger.info("Campo de contrase√±a encontrado con selector: (By.ID, 'password')")
            
            logger.info("Formulario de login cargado exitosamente")
            return True
            
        except Exception as e:
            logger.error(f"Error esperando el formulario de login: {str(e)}")
            return False
    
    def perform_login(self, email, password):
        """
        Realiza el proceso de login en Tuboleta simulando comportamiento humano
        
        Returns:
            bool: True si el login fue exitoso, False en caso contrario
        """
        try:
            logger.info("üîê Iniciando proceso de login...")
            
            # Simular comportamiento humano antes del login
            self.simulate_mouse_movements()
            time.sleep(random.uniform(1, 3))
            
            # Buscar campo de email/username
            logger.info("üîç Buscando campo de usuario con id='login'...")
            try:
                username_field = WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.ID, "login"))
                )
                logger.info("‚úÖ Campo de usuario encontrado")
            except Exception as e:
                logger.error(f"‚ùå No se encontr√≥ el campo de usuario con id='login': {str(e)}")
                return False
            
            # Buscar campo de contrase√±a
            logger.info("üîç Buscando campo de contrase√±a con id='password'...")
            try:
                password_field = self.driver.find_element(By.ID, "password")
                logger.info("‚úÖ Campo de contrase√±a encontrado")
            except Exception as e:
                logger.error(f"‚ùå No se encontr√≥ el campo de contrase√±a con id='password': {str(e)}")
                return False
            
            # Esperar un momento antes de empezar a escribir
            logger.info("‚è≥ Esperando antes de empezar a escribir...")
            time.sleep(random.uniform(1, 2))
            
            # Simular comportamiento humano: mover mouse al campo de usuario
            logger.info("üñ±Ô∏è Moviendo mouse al campo de usuario...")
            actions = ActionChains(self.driver)
            actions.move_to_element(username_field).pause(random.uniform(0.3, 0.7)).perform()
            
            # Hacer clic en el campo de usuario
            username_field.click()
            time.sleep(random.uniform(0.2, 0.5))
            
            # Escribir usuario con comportamiento humano
            logger.info("‚úèÔ∏è Escribiendo nombre de usuario...")
            self.human_type(username_field, email)
            logger.info(f"‚úÖ Usuario ingresado: {email}")
            
            # Pausa humana antes de ir al siguiente campo
            time.sleep(random.uniform(0.5, 1.5))
            
            # Simular comportamiento humano: mover mouse al campo de contrase√±a
            logger.info("üñ±Ô∏è Moviendo mouse al campo de contrase√±a...")
            actions.move_to_element(password_field).pause(random.uniform(0.3, 0.7)).perform()
            
            # Hacer clic en el campo de contrase√±a
            password_field.click()
            time.sleep(random.uniform(0.2, 0.5))
            
            # Escribir contrase√±a con comportamiento humano
            logger.info("‚úèÔ∏è Escribiendo contrase√±a...")
            self.human_type(password_field, password)
            logger.info("‚úÖ Contrase√±a ingresada")
            
            # Pausa humana antes de hacer clic en el bot√≥n
            time.sleep(random.uniform(0.5, 2))
            
            # Buscar y hacer clic en el bot√≥n de continue
            logger.info("üîç Buscando bot√≥n con id='continue_button'...")
            try:
                continue_button = self.driver.find_element(By.ID, "continue_button")
                logger.info("‚úÖ Bot√≥n de continue encontrado")
            except Exception as e:
                logger.error(f"‚ùå No se encontr√≥ el bot√≥n con id='continue_button': {str(e)}")
                return False
            
            # Simular comportamiento humano: mover mouse al bot√≥n y hacer clic
            logger.info("üñ±Ô∏è Moviendo mouse al bot√≥n de continue...")
            actions.move_to_element(continue_button).pause(random.uniform(0.5, 1)).perform()
            
            # Hacer clic en el bot√≥n
            continue_button.click()
            logger.info("‚úÖ Bot√≥n de continue clickeado (simulando comportamiento humano)")
            
            # Esperar 5 segundos despu√©s del login como solicitado
            logger.info("‚è≥ Esperando 5 segundos despu√©s del login...")
            time.sleep(5)
            
            # Verificar si el login fue exitoso
            logger.info("üîç Verificando si el login fue exitoso...")
            
            # Obtener la URL actual
            current_url = self.driver.current_url
            logger.info(f"üîó URL actual despu√©s del login: {current_url}")
            
            # Si la URL cambi√≥ o no estamos en la p√°gina de login, el login fue exitoso
            if current_url != self.login_url and "login" not in current_url:
                logger.info("‚úÖ Login exitoso - URL cambi√≥")
                return True
            else:
                logger.warning("‚ö†Ô∏è Posible fallo en login - verificando elementos de error...")
                return True  # Continuar de todas formas para intentar ir al dashboard
                
        except Exception as e:
            logger.error(f"‚ùå Error durante el proceso de login: {str(e)}")
            return False
    
    def login_with_specific_credential(self, credential_index):
        """Realiza el login con una credencial espec√≠fica"""
        if credential_index >= len(self.credentials):
            logger.error(f"√çndice de credencial inv√°lido: {credential_index}")
            return False
            
        credential = self.credentials[credential_index]
        email = credential["email"]
        password = credential["password"]
        
        logger.info(f"Intentando login con credencial {credential_index + 1}/{len(self.credentials)}: {email}")
        
        # Intentar login con esta credencial
        if self.perform_login(email, password):
            self.current_credential_index = credential_index
            logger.info(f"Login exitoso con credencial: {email}")
            return True
        else:
            logger.warning(f"Login fall√≥ con credencial: {email}")
            return False
    
    def get_current_credential_info(self):
        """Obtiene informaci√≥n sobre la credencial actualmente en uso"""
        if self.current_credential_index < len(self.credentials):
            current_cred = self.credentials[self.current_credential_index]
            return f"{current_cred['email']}"
        return "Ninguna"
    
    def close_driver(self):
        """Cierra el driver del navegador"""
        if self.driver:
            self.driver.quit()
            logger.info("üîí Driver cerrado")
    
    def navigate_to_dashboard(self):
        """Navega al dashboard de reportes"""
        try:
            logger.info("üåê Navegando al dashboard de reportes...")
            logger.info(f"üìç URL: {self.dashboard_url}")
            
            self.driver.get(self.dashboard_url)
            
            # Esperar 5 segundos como solicitado
            logger.info("‚è≥ Esperando 5 segundos en el dashboard...")
            time.sleep(5)
            
            # Obtener la URL actual
            current_url = self.driver.current_url
            logger.info(f"üîó URL actual en dashboard: {current_url}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error navegando al dashboard: {str(e)}")
            return False
    
    def click_table_elements(self):
        """Busca y hace clic en TODOS los spans que contienen SVG dentro de los elementos td con class='sc-drKuOJ cJfebM sc-likbZx gmUyDe' SIMULT√ÅNEAMENTE para mayor velocidad"""
        try:
            logger.info("üîç Buscando elementos 'td' con class='sc-drKuOJ cJfebM sc-likbZx gmUyDe' para clickear SIMULT√ÅNEAMENTE...")
            
            # Buscar elementos td con la clase espec√≠fica
            table_elements = self.driver.find_elements(By.CSS_SELECTOR, "td.sc-drKuOJ.cJfebM.sc-likbZx.gmUyDe")
            
            logger.info(f"üìã Encontrados {len(table_elements)} elementos td con la clase especificada")
            print(f"\n" + "="*80)
            print(f"ELEMENTOS TD ENCONTRADOS CON CLASS='sc-drKuOJ cJfebM sc-likbZx gmUyDe'")
            print("="*80)
            
            if not table_elements:
                logger.warning("‚ö†Ô∏è No se encontraron elementos td con la clase especificada")
                print("‚ö†Ô∏è NO SE ENCONTRARON ELEMENTOS TD CON ESA CLASE")
                return False
            else:
                # M√âTODO 1: Intentar clickear todos simult√°neamente con JavaScript
                logger.info("üöÄ Intentando clickear todos los elementos SIMULT√ÅNEAMENTE con JavaScript...")
                
                try:
                    # Crear script JavaScript para hacer clic en todos los spans simult√°neamente
                    js_script = """
                    var elements = document.querySelectorAll('td.sc-drKuOJ.cJfebM.sc-likbZx.gmUyDe span');
                    var clickedCount = 0;
                    
                    for (var i = 0; i < elements.length; i++) {
                        try {
                            elements[i].click();
                            clickedCount++;
                        } catch (e) {
                            console.log('Error clicking element ' + i + ': ' + e);
                        }
                    }
                    
                    return clickedCount;
                    """
                    
                    # Ejecutar el script JavaScript
                    clicked_count = self.driver.execute_script(js_script)
                    
                    logger.info(f"‚úÖ JavaScript ejecutado exitosamente: {clicked_count} elementos clickeados simult√°neamente")
                    print(f"‚úÖ JAVASCRIPT: {clicked_count}/{len(table_elements)} elementos clickeados SIMULT√ÅNEAMENTE")
                    
                    # Esperar un momento para que se procesen todos los clics
                    logger.info("‚è≥ Esperando 2 segundos para que se procesen todos los clics simult√°neos...")
                    time.sleep(2)
                    
                    return True
                    
                except Exception as js_error:
                    logger.warning(f"‚ö†Ô∏è Error con JavaScript simult√°neo: {str(js_error)}")
                    logger.info("üîÑ Recurriendo a m√©todo secuencial como respaldo...")
                    
                    # M√âTODO 2: M√©todo secuencial como respaldo
                    logger.info("üîÑ M√âTODO DE RESPALDO: Clickando elementos uno por uno...")
                    
                    clicked_count = 0
                    for i, td_element in enumerate(table_elements):
                        try:
                            # Buscar el span que contiene el SVG dentro del td
                            span_element = td_element.find_element(By.TAG_NAME, "span")
                            
                            # Obtener informaci√≥n del elemento antes de hacer clic
                            text = td_element.text.strip()
                            
                            # Hacer scroll al elemento para asegurar que est√© visible
                            self.driver.execute_script("arguments[0].scrollIntoView(true);", span_element)
                            time.sleep(0.1)
                            
                            # Simular comportamiento humano antes del clic
                            actions = ActionChains(self.driver)
                            actions.move_to_element(span_element).pause(random.uniform(0.1, 0.3)).perform()
                            
                            # Hacer clic en el span
                            span_element.click()
                            clicked_count += 1
                            
                            logger.info(f"‚úÖ Span en elemento td {i+1} clickeado exitosamente: '{text}'")
                            
                            # Pausa m√≠nima entre clics para mayor velocidad
                            time.sleep(random.uniform(0.2, 0.5))
                            
                        except Exception as e:
                            logger.error(f"‚ùå Error clickeando span en elemento td {i+1}: {str(e)}")
                            continue
                    
                    logger.info(f"‚úÖ M√©todo de respaldo completado: {clicked_count}/{len(table_elements)} spans")
                
                # Esperar un momento despu√©s de hacer todos los clics
                logger.info("‚è≥ Esperando 3 segundos despu√©s de hacer todos los clics...")
                time.sleep(3)
                
                return True
            
        except Exception as e:
            logger.error(f"‚ùå Error buscando/clickeando spans en elementos td: {str(e)}")
            return False

    def find_performance_links(self):
        """Busca y lista todos los elementos 'a' con class='sc-dHmInP stx-PerformanceLink hQhYXZ'"""
        try:
            logger.info("üîç Buscando elementos 'a' con class='sc-dHmInP stx-PerformanceLink hQhYXZ'...")
            
            # Buscar elementos con la clase espec√≠fica
            performance_links = self.driver.find_elements(By.CSS_SELECTOR, "a.sc-dHmInP.stx-PerformanceLink.hQhYXZ")
            
            logger.info(f"üìã Encontrados {len(performance_links)} elementos con la clase especificada")
            
            if not performance_links:
                logger.warning("‚ö†Ô∏è No se encontraron elementos con la clase especificada")
                
                # Intentar buscar elementos similares para debug
                logger.info("üîç Buscando elementos similares para debug...")
                
                # Buscar todos los enlaces
                all_links = self.driver.find_elements(By.TAG_NAME, "a")
                logger.info(f"üìã Total de enlaces encontrados: {len(all_links)}")
                        
            else:
                for i, link in enumerate(performance_links):
                    try:
                        # Obtener informaci√≥n del elemento
                        href = link.get_attribute("href")
                        text = link.text.strip()
                        title = link.get_attribute("title")
                        
                        logger.info(f"‚úÖ Elemento {i+1}: href='{href}', texto='{text}', title='{title}'")
                        
                    except Exception as e:
                        logger.error(f"‚ùå Error procesando elemento {i+1}: {str(e)}")
                        continue
            
            return performance_links
            
        except Exception as e:
            logger.error(f"‚ùå Error buscando elementos de performance: {str(e)}")
            return []

    def find_and_print_tables_in_section_elements(self):
        """Busca elementos con class='sc-jkCMRl perf-dashboard-SectionElement kjnvWY', verifica si tienen tablas y las imprime como DataFrames"""
        try:
            logger.info("üîç Buscando elementos con class='sc-jkCMRl perf-dashboard-SectionElement kjnvWY'...")
            
            # Obtener el HTML de la p√°gina
            page_source = self.driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            
            # Buscar todos los elementos de secci√≥n
            section_elements = soup.find_all('div', class_='sc-jkCMRl perf-dashboard-SectionElement kjnvWY')
            logger.info(f"üìä Encontrados {len(section_elements)} elementos de secci√≥n en la p√°gina")
            
            # Lista para almacenar todos los DataFrames encontrados
            all_dataframes = []
            
            for i, section in enumerate(section_elements):
                logger.info(f"üîç Procesando elemento de secci√≥n {i+1}...")
                # Buscar tablas dentro del elemento de secci√≥n
                tables = section.find_all('table')
                logger.info(f"üìä Encontradas {len(tables)} tablas en el elemento de secci√≥n {i+1}")
                
                for j, table in enumerate(tables):
                    # Convertir la tabla a DataFrame
                    df = pd.read_html(str(table))[0]
                    
                    # Agregar informaci√≥n del DataFrame
                    df_info = {
                        'section': i+1,
                        'table': j+1,
                        'dataframe': df,
                        'has_seat_category': False
                    }
                    
                    # Verificar si tiene 'Categor√≠a de asiento'
                    if 'Categor√≠a de asiento' in df.columns:
                        df_info['has_seat_category'] = True
                        logger.info(f"‚úÖ DataFrame {j+1} en secci√≥n {i+1} contiene 'Categor√≠a de asiento'")
                    
                    all_dataframes.append(df_info)
                    
                    print(f"\nüìä DATAFRAME DE LA TABLA {j+1} EN ELEMENTO DE SECCI√ìN {i+1}:")
                    print(df)
                    logger.info(f"‚úÖ Tabla {j+1} en elemento de secci√≥n {i+1} impresa como DataFrame")
            
            # Guardar los DataFrames en la instancia para uso posterior
            self.all_dataframes = all_dataframes
            
            # Buscar y guardar el DataFrame con 'Categor√≠a de asiento'
            self.save_dataframe_with_seat_category_to_json(all_dataframes)
            
        except Exception as e:
            logger.error(f"‚ùå Error buscando/imprimiendo tablas en elementos de secci√≥n: {str(e)}")

    def save_dataframe_with_seat_category_to_json(self, dataframes):
        """Guarda siempre el cuarto DataFrame (elemento de secci√≥n 4) en JSON"""
        try:
            logger.info("üîç Buscando el cuarto DataFrame (elemento de secci√≥n 4) para guardar en JSON...")
            
            # Buscar el DataFrame de la secci√≥n 4
            section_4_df = None
            for df_info in dataframes:
                if df_info['section'] == 4:
                    section_4_df = df_info
                    break
            
            if section_4_df:
                logger.info(f"‚úÖ DataFrame encontrado en secci√≥n {section_4_df['section']}, tabla {section_4_df['table']}")
                
                # Obtener el nombre del archivo del t√≠tulo de la p√°gina
                page_source = self.driver.page_source
                soup = BeautifulSoup(page_source, 'html.parser')
                div_title = soup.find('div', class_='sc-fQejPQ stx-ViewTitle AmAsl')
                
                if div_title:
                    # Limpiar el t√≠tulo para hacer un nombre de archivo v√°lido
                    raw_title = div_title.text.strip()
                    logger.info(f"üìù T√≠tulo original: '{raw_title}'")
                    
                    # Reemplazar caracteres inv√°lidos
                    clean_title = raw_title.replace('>', '-').replace('<', '-').replace(':', '-').replace('*', '-')
                    clean_title = clean_title.replace('?', '-').replace('"', '-').replace('|', '-').replace('/', '-')
                    clean_title = clean_title.replace('\\', '-').replace('|', '-')
                    
                    # Eliminar espacios m√∫ltiples y reemplazar por uno solo
                    clean_title = re.sub(r'\s+', ' ', clean_title).strip()
                    
                    # Eliminar guiones m√∫ltiples consecutivos y reemplazar por uno solo
                    clean_title = re.sub(r'-+', '-', clean_title)
                    
                    # Eliminar guiones al inicio y final
                    clean_title = clean_title.strip('-')
                    
                    # Eliminar espec√≠ficamente el patr√≥n " - " (espacio, gui√≥n, espacio) entre texto y fecha
                    clean_title = re.sub(r'\s+-\s+', ' ', clean_title)
                    
                    # Limitar longitud del nombre
                    if len(clean_title) > 50:
                        clean_title = clean_title[:50]
                    
                    json_filename = f"{clean_title}.json"
                    logger.info(f"üìù T√≠tulo limpio para archivo: '{clean_title}'")
                else:
                    json_filename = f"seccion_{section_4_df['section']}_tabla_{section_4_df['table']}.json"
                
                # Guardar DataFrame en JSON
                # Limpiar nombres de columnas antes de guardar
                df_to_save = section_4_df['dataframe'].copy()
                
                # Limpiar nombres de columnas multinivel
                new_columns = []
                seen_columns = {}  # Para rastrear columnas duplicadas
                
                for i, col in enumerate(df_to_save.columns):
                    if isinstance(col, tuple):
                        # Si es una tupla, tomar solo la segunda parte
                        if len(col) >= 2:
                            base_name = col[1]
                            # Agregar prefijo del primer nivel si es necesario
                            if len(col) >= 1:
                                prefix = col[0]
                                if prefix and prefix != 'Unnamed: 0_level_0' and prefix != 'Unnamed: 1_level_0':
                                    base_name = f"{prefix}_{base_name}"
                        else:
                            base_name = str(col)
                    else:
                        # Si no es tupla, usar el nombre tal como est√°
                        base_name = str(col)
                    
                    # Hacer la columna √∫nica
                    if base_name in seen_columns:
                        seen_columns[base_name] += 1
                        base_name = f"{base_name}_{seen_columns[base_name]}"
                    else:
                        seen_columns[base_name] = 0
                    
                    new_columns.append(base_name)
                
                # Asignar los nuevos nombres de columnas
                df_to_save.columns = new_columns
                
                logger.info(f"üìä Columnas originales: {list(section_4_df['dataframe'].columns)}")
                logger.info(f"üìä Columnas limpias: {new_columns}")
                
                json_data = df_to_save.to_json(orient='records', force_ascii=False, indent=2)
                json_path = os.path.join(self.download_folder, json_filename)
                
                with open(json_path, 'w', encoding='utf-8') as f:
                    f.write(json_data)
                
                logger.info(f"‚úÖ DataFrame de secci√≥n 4 guardado en '{json_path}'")
                print(f"\nüíæ DATAFRAME GUARDADO EN JSON:")
                print(f"üìÅ Archivo: {json_path}")
                print(f"üìä Secci√≥n: {section_4_df['section']}")
                print(f"üìã Tabla: {section_4_df['table']}")
                print(f"üìà Filas: {len(section_4_df['dataframe'])}")
                print(f"üìä Columnas: {list(section_4_df['dataframe'].columns)}")
                
            else:
                logger.warning("‚ö†Ô∏è No se encontr√≥ el DataFrame de la secci√≥n 4")
                print("‚ö†Ô∏è NO SE ENCONTR√ì EL DATAFRAME DE LA SECCI√ìN 4")
                
        except Exception as e:
            logger.error(f"‚ùå Error guardando DataFrame en JSON: {str(e)}")
            print(f"‚ùå Error guardando DataFrame en JSON: {str(e)}")

    def click_first_performance_link_and_wait(self):
        """Hace clic en el primer elemento 'a' con class='sc-dHmInP stx-PerformanceLink hQhYXZ', espera 10 segundos y busca elementos de secci√≥n"""
        try:
            logger.info("üîç Buscando el primer elemento 'a' con class='sc-dHmInP stx-PerformanceLink hQhYXZ' para hacer clic...")
            
            # Buscar elementos con la clase espec√≠fica
            performance_links = self.driver.find_elements(By.CSS_SELECTOR, "a.sc-dHmInP.stx-PerformanceLink.hQhYXZ")
            
            if performance_links:
                first_link = performance_links[0]
                
                # Obtener informaci√≥n del elemento
                href = first_link.get_attribute("href")
                text = first_link.text.strip()
                class_attr = first_link.get_attribute("class")
                
                print(f"\nüìã PRIMER ENLACE DE PERFORMANCE:")
                print(f"  üîó Href: {href}")
                print(f"  üìù Texto: '{text}'")
                print(f"  üé® Class: '{class_attr}'")
                
                logger.info(f"‚úÖ Primer enlace de performance: href='{href}', texto='{text}', class='{class_attr}'")
                
                # Hacer clic en el enlace
                first_link.click()
                logger.info("‚úÖ Primer enlace de performance clickeado exitosamente")
                
                # Esperar 10 segundos despu√©s de hacer clic
                logger.info("‚è≥ Esperando 10 segundos despu√©s de hacer clic en el primer enlace de performance...")
                time.sleep(10)
                
                # Buscar e imprimir tablas en elementos de secci√≥n
                self.find_and_print_tables_in_section_elements()
            else:
                logger.warning("‚ö†Ô∏è No se encontraron enlaces de performance con la clase especificada")
                print("‚ö†Ô∏è NO SE ENCONTRARON ENLACES DE PERFORMANCE CON ESA CLASE")
        except Exception as e:
            logger.error(f"‚ùå Error haciendo clic en el primer enlace de performance: {str(e)}")
            print(f"‚ùå Error haciendo clic en el primer enlace de performance: {str(e)}")

    def process_all_performance_events(self, performance_links, email):
        """Procesa todos los eventos de performance uno por uno"""
        try:
            logger.info(f"üé≠ Iniciando procesamiento de {len(performance_links)} eventos de performance...")
            
            events_processed = 0
            events_failed = 0
            
            for i, link in enumerate(performance_links):
                try:
                    # Obtener informaci√≥n del evento antes de hacer clic
                    event_text = link.text.strip()
                    event_href = link.get_attribute("href")
                    
                    logger.info(f"üé´ PROCESANDO EVENTO {i+1}/{len(performance_links)}: {event_text}")
                    logger.info("=" * 60)
                    
                    # Hacer scroll al elemento para asegurar que est√© visible
                    self.driver.execute_script("arguments[0].scrollIntoView(true);", link)
                    time.sleep(1)
                    
                    # Hacer clic en el enlace del evento
                    logger.info(f"üñ±Ô∏è Haciendo clic en evento: {event_text}")
                    link.click()
                    
                    # Esperar a que se cargue la informaci√≥n del evento
                    logger.info("‚è≥ Esperando 10 segundos para que cargue la informaci√≥n del evento...")
                    time.sleep(10)
                    
                    # Procesar los datos del evento actual
                    logger.info(f"üìä Extrayendo datos del evento: {event_text}")
                    self.extract_and_save_event_data(event_text, email, i+1)
                    
                    events_processed += 1
                    logger.info(f"‚úÖ Evento {i+1} procesado exitosamente: {event_text}")
                    
                    # Si no es el √∫ltimo evento, navegar de regreso al dashboard
                    if i < len(performance_links) - 1:
                        logger.info("üîÑ Navegando de regreso al dashboard para el siguiente evento...")
                        self.navigate_to_dashboard()
                        time.sleep(3)
                        
                        # Volver a hacer clic en los elementos td para expandir la lista
                        logger.info("üñ±Ô∏è Expandiendo lista de eventos nuevamente...")
                        self.click_table_elements()
                        time.sleep(2)
                        
                        # Obtener los enlaces actualizados (importante por cambios en el DOM)
                        updated_links = self.driver.find_elements(By.CSS_SELECTOR, "a.sc-dHmInP.stx-PerformanceLink.hQhYXZ")
                        if len(updated_links) > i + 1:
                            performance_links = updated_links
                        else:
                            logger.warning(f"‚ö†Ô∏è No se pudieron obtener enlaces actualizados. Usando enlaces originales.")
                    
                    logger.info("=" * 60)
                    
                except Exception as e:
                    events_failed += 1
                    logger.error(f"‚ùå Error procesando evento {i+1} ({event_text}): {str(e)}")
                    continue
            
            # Resumen final del procesamiento de eventos
            logger.info("üéâ RESUMEN DE PROCESAMIENTO DE EVENTOS:")
            logger.info(f"  ‚úÖ Eventos procesados exitosamente: {events_processed}")
            logger.info(f"  ‚ùå Eventos que fallaron: {events_failed}")
            logger.info(f"  üìä Total eventos: {len(performance_links)}")
            logger.info(f"  üìà Tasa de √©xito: {(events_processed/len(performance_links)*100):.1f}%")
            
        except Exception as e:
            logger.error(f"‚ùå Error en el procesamiento general de eventos: {str(e)}")

    def extract_and_save_event_data(self, event_name, email, event_number):
        """Extrae y guarda los datos de un evento espec√≠fico"""
        try:
            logger.info(f"üìä Extrayendo datos del evento: {event_name}")
            
            # Buscar e imprimir tablas en elementos de secci√≥n
            self.find_and_print_tables_in_section_elements_for_event(event_name, email, event_number)
            
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo datos del evento {event_name}: {str(e)}")

    def find_and_print_tables_in_section_elements_for_event(self, event_name, email, event_number):
        """Busca elementos de secci√≥n y guarda datos espec√≠ficos para un evento"""
        try:
            logger.info(f"üîç Buscando elementos de secci√≥n para evento: {event_name}")
            
            # Obtener el HTML de la p√°gina
            page_source = self.driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            
            # Buscar todos los elementos de secci√≥n
            section_elements = soup.find_all('div', class_='sc-jkCMRl perf-dashboard-SectionElement kjnvWY')
            logger.info(f"üìä Encontrados {len(section_elements)} elementos de secci√≥n para {event_name}")
            
            # Lista para almacenar todos los DataFrames encontrados
            all_dataframes = []
            
            for i, section in enumerate(section_elements):
                logger.info(f"üîç Procesando elemento de secci√≥n {i+1} para evento {event_name}...")
                # Buscar tablas dentro del elemento de secci√≥n
                tables = section.find_all('table')
                logger.info(f"üìä Encontradas {len(tables)} tablas en el elemento de secci√≥n {i+1}")
                
                for j, table in enumerate(tables):
                    # Convertir la tabla a DataFrame
                    df = pd.read_html(str(table))[0]
                    
                    # Agregar informaci√≥n del DataFrame
                    df_info = {
                        'section': i+1,
                        'table': j+1,
                        'dataframe': df,
                        'event_name': event_name,
                        'event_number': event_number,
                        'email': email,
                        'has_seat_category': False
                    }
                    
                    # Verificar si tiene 'Categor√≠a de asiento'
                    if 'Categor√≠a de asiento' in df.columns:
                        df_info['has_seat_category'] = True
                        logger.info(f"‚úÖ DataFrame {j+1} en secci√≥n {i+1} contiene 'Categor√≠a de asiento'")
                    
                    all_dataframes.append(df_info)
                    
                    print(f"\nüìä DATAFRAME DE LA TABLA {j+1} EN SECCI√ìN {i+1} - EVENTO: {event_name}")
                    print(df.head(10))  # Mostrar solo las primeras 10 filas para no saturar
                    logger.info(f"‚úÖ Tabla {j+1} en secci√≥n {i+1} procesada para evento {event_name}")
            
            # Guardar los datos del evento
            self.save_event_dataframes_to_json(all_dataframes, event_name, email, event_number)
            
        except Exception as e:
            logger.error(f"‚ùå Error procesando tablas para evento {event_name}: {str(e)}")

    def save_event_dataframes_to_json(self, dataframes, event_name, email, event_number):
        """Guarda los DataFrames de un evento espec√≠fico en archivos JSON separados"""
        try:
            logger.info(f"üíæ Guardando datos del evento: {event_name}")
            
            # Limpiar el nombre del evento para crear nombres de archivo v√°lidos
            clean_event_name = event_name.replace('/', '-').replace(':', '-').replace(' ', '_')
            clean_event_name = re.sub(r'[^\w\-_.]', '', clean_event_name)
            
            email_clean = email.split('@')[0].replace('.', '_')
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            events_saved = 0
            
            # Buscar y guardar espec√≠ficamente la secci√≥n 4 (que suele tener los datos principales)
            section_4_df = None
            for df_info in dataframes:
                if df_info['section'] == 4:
                    section_4_df = df_info
                    break
            
            if section_4_df:
                # Guardar secci√≥n 4 (datos principales)
                filename = f"tuboleta_{clean_event_name}_seccion4_{email_clean}_evento{event_number}_{timestamp}.json"
                self.save_single_dataframe_to_json(section_4_df, filename, "Secci√≥n 4 - Datos principales")
                events_saved += 1
            
            # Guardar tambi√©n secci√≥n 1 si tiene categor√≠as de asiento
            section_1_df = None
            for df_info in dataframes:
                if df_info['section'] == 1 and df_info.get('has_seat_category', False):
                    section_1_df = df_info
                    break
            
            if section_1_df:
                # Guardar secci√≥n 1 (categor√≠as de asiento)
                filename = f"tuboleta_{clean_event_name}_asientos_{email_clean}_evento{event_number}_{timestamp}.json"
                self.save_single_dataframe_to_json(section_1_df, filename, "Secci√≥n 1 - Categor√≠as de asiento")
                events_saved += 1
            
            # Guardar secci√≥n 3 (tarifas) si existe
            section_3_df = None
            for df_info in dataframes:
                if df_info['section'] == 3:
                    section_3_df = df_info
                    break
            
            if section_3_df:
                # Guardar secci√≥n 3 (tarifas)
                filename = f"tuboleta_{clean_event_name}_tarifas_{email_clean}_evento{event_number}_{timestamp}.json"
                self.save_single_dataframe_to_json(section_3_df, filename, "Secci√≥n 3 - Tarifas")
                events_saved += 1
            
            logger.info(f"‚úÖ Evento {event_name}: {events_saved} archivos JSON guardados exitosamente")
            
        except Exception as e:
            logger.error(f"‚ùå Error guardando datos del evento {event_name}: {str(e)}")

    def save_single_dataframe_to_json(self, df_info, filename, description):
        """Guarda un DataFrame individual en JSON"""
        try:
            # Limpiar nombres de columnas antes de guardar
            df_to_save = df_info['dataframe'].copy()
            
            # Limpiar nombres de columnas multinivel
            new_columns = []
            seen_columns = {}
            
            for i, col in enumerate(df_to_save.columns):
                if isinstance(col, tuple):
                    if len(col) >= 2:
                        base_name = col[1]
                        if len(col) >= 1:
                            prefix = col[0]
                            if prefix and prefix != 'Unnamed: 0_level_0' and prefix != 'Unnamed: 1_level_0':
                                base_name = f"{prefix}_{base_name}"
                    else:
                        base_name = str(col)
                else:
                    base_name = str(col)
                
                # Hacer la columna √∫nica
                if base_name in seen_columns:
                    seen_columns[base_name] += 1
                    base_name = f"{base_name}_{seen_columns[base_name]}"
                else:
                    seen_columns[base_name] = 0
                
                new_columns.append(base_name)
            
            # Asignar los nuevos nombres de columnas
            df_to_save.columns = new_columns
            
            # Crear estructura de datos para JSON
            data = {
                'metadata': {
                    'evento': df_info['event_name'],
                    'numero_evento': df_info['event_number'],
                    'usuario_utilizado': df_info['email'],
                    'seccion': df_info['section'],
                    'tabla': df_info['table'],
                    'descripcion': description,
                    'fecha_extraccion': datetime.now().isoformat(),
                    'url_origen': self.driver.current_url
                },
                'total_registros': len(df_to_save),
                'datos': df_to_save.to_dict('records')
            }
            
            # Guardar en archivo
            filepath = os.path.join(self.download_folder, filename)
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"üíæ {description} guardado en: {filename}")
            logger.info(f"üìä Registros: {len(df_to_save)} | Columnas: {len(new_columns)}")
            
        except Exception as e:
            logger.error(f"‚ùå Error guardando {description}: {str(e)}")
    
    def check_dashboard_access(self):
        """Verifica si el dashboard es accesible y muestra informaci√≥n √∫til"""
        try:
            logger.info("Verificando acceso al dashboard...")
            
            # Buscar elementos espec√≠ficos del dashboard
            dashboard_elements = []
            
            # Buscar tablas
            tables = self.driver.find_elements(By.TAG_NAME, "table")
            dashboard_elements.append(f"Tablas encontradas: {len(tables)}")
            
            # Buscar elementos de navegaci√≥n
            nav_elements = self.driver.find_elements(By.CSS_SELECTOR, "nav, .nav, .navigation, .menu")
            dashboard_elements.append(f"Elementos de navegaci√≥n: {len(nav_elements)}")
            
            # Buscar contenido principal
            main_content = self.driver.find_elements(By.CSS_SELECTOR, "main, .main, .content, .dashboard")
            dashboard_elements.append(f"Contenido principal: {len(main_content)}")
            
            # Buscar botones
            buttons = self.driver.find_elements(By.TAG_NAME, "button")
            dashboard_elements.append(f"Botones: {len(buttons)}")
            
            # Buscar enlaces
            links = self.driver.find_elements(By.TAG_NAME, "a")
            dashboard_elements.append(f"Enlaces: {len(links)}")
            
            logger.info("Elementos encontrados en el dashboard:")
            for element in dashboard_elements:
                logger.info(f"  - {element}")
            
            return True
            
        except Exception as e:
            logger.error(f"Error verificando acceso al dashboard: {str(e)}")
            return False
    
    def debug_available_links(self):
        """Debug: Muestra todos los enlaces disponibles en la p√°gina actual"""
        try:
            logger.info("=== DEBUG: Analizando enlaces disponibles ===")
            
            # Informaci√≥n general de la p√°gina
            current_url = self.driver.current_url
            page_title = self.driver.title
            logger.info(f"URL actual: {current_url}")
            logger.info(f"T√≠tulo de la p√°gina: {page_title}")
            
            # Buscar todos los enlaces
            links = self.driver.find_elements(By.TAG_NAME, "a")
            logger.info(f"Total de enlaces encontrados: {len(links)}")
            
            dashboard_links = []
            account_links = []
            navigation_links = []
            
            for i, link in enumerate(links):
                try:
                    link_text = link.text.strip()
                    link_href = link.get_attribute("href")
                    link_class = link.get_attribute("class")
                    link_id = link.get_attribute("id")
                    
                    # Mostrar enlaces importantes
                    if link_text or (link_href and "dashboard" in link_href.lower()):
                        logger.info(f"Enlace {i+1}: text='{link_text}', href='{link_href}', class='{link_class}', id='{link_id}'")
                    
                    # Identificar enlaces relacionados con dashboard
                    if (link_text and "dashboard" in link_text.lower()) or (link_href and "dashboard" in link_href.lower()):
                        dashboard_links.append({
                            'text': link_text,
                            'href': link_href,
                            'class': link_class,
                            'id': link_id
                        })
                    
                    # Identificar enlaces relacionados con account
                    if (link_text and "account" in link_text.lower()) or (link_href and "account" in link_href.lower()):
                        account_links.append({
                            'text': link_text,
                            'href': link_href,
                            'class': link_class,
                            'id': link_id
                        })
                    
                    # Identificar enlaces de navegaci√≥n
                    if link_text and any(nav in link_text.lower() for nav in ['menu', 'nav', 'home', 'inicio', 'report', 'reporte']):
                        navigation_links.append({
                            'text': link_text,
                            'href': link_href,
                            'class': link_class,
                            'id': link_id
                        })
                        
                except Exception as e:
                    logger.error(f"Error analizando enlace {i+1}: {str(e)}")
                    continue
            
            # Mostrar resumen de enlaces importantes
            if dashboard_links:
                logger.info("=== ENLACES DASHBOARD ENCONTRADOS ===")
                for i, link in enumerate(dashboard_links):
                    logger.info(f"Dashboard Link {i+1}: text='{link['text']}', href='{link['href']}'")
            else:
                logger.warning("‚ö†Ô∏è No se encontraron enlaces espec√≠ficos de Dashboard")
            
            if account_links:
                logger.info("=== ENLACES ACCOUNT ENCONTRADOS ===")
                for i, link in enumerate(account_links):
                    logger.info(f"Account Link {i+1}: text='{link['text']}', href='{link['href']}'")
            
            if navigation_links:
                logger.info("=== ENLACES DE NAVEGACI√ìN ENCONTRADOS ===")
                for i, link in enumerate(navigation_links):
                    logger.info(f"Navigation Link {i+1}: text='{link['text']}', href='{link['href']}'")
            
            # Buscar elementos de navegaci√≥n
            try:
                nav_elements = self.driver.find_elements(By.CSS_SELECTOR, "nav, .nav, .navigation, .menu, .navbar")
                logger.info(f"Elementos de navegaci√≥n encontrados: {len(nav_elements)}")
                
                for i, nav in enumerate(nav_elements):
                    nav_text = nav.text.strip()
                    if nav_text:
                        logger.info(f"Nav {i+1}: '{nav_text[:100]}...'")
            except:
                pass
            
            logger.info("=== FIN DEBUG ENLACES ===")
            
        except Exception as e:
            logger.error(f"Error en debug de enlaces: {str(e)}")
    
    def get_dashboard_table_data(self):
        """Extrae los datos de la tabla del dashboard"""
        try:
            logger.info("Extrayendo datos de la tabla del dashboard...")
            
            # Esperar a que la tabla cargue
            time.sleep(8)
            
            # Intentar diferentes selectores para encontrar la tabla
            table = None
            selectors_to_try = [
                "table.sc-drMfKT.dashboard-Table",
                "table.dashboard-Table",
                "table.sc-drMfKT",
                "table[class*='dashboard']",
                "table[class*='Table']",
                "table"
            ]
            
            for selector in selectors_to_try:
                try:
                    logger.info(f"Intentando selector: {selector}")
                    table = WebDriverWait(self.driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                    )
                    logger.info(f"‚úÖ Tabla encontrada con selector: {selector}")
                    break
                except:
                    continue
            
            if not table:
                logger.error("‚ùå No se pudo encontrar la tabla del dashboard")
                return []
            
            # Extraer datos de las filas
            rows = table.find_elements(By.CSS_SELECTOR, "tbody tr")
            logger.info(f"Encontradas {len(rows)} filas en la tabla")
            
            if len(rows) == 0:
                # Intentar buscar filas directamente
                rows = table.find_elements(By.TAG_NAME, "tr")
                logger.info(f"Buscando filas directamente: {len(rows)} encontradas")
            
            table_data = []
            
            for i, row in enumerate(rows):
                try:
                    # Obtener todas las celdas de la fila
                    cells = row.find_elements(By.TAG_NAME, "td")
                    
                    if len(cells) >= 3:  # M√≠nimo 3 columnas para ser una fila v√°lida
                        row_type = self._get_row_type(row)
                        
                        # Solo incluir eventos reales, no subtotales ni totales
                        if row_type == "evento":
                            row_data = {
                                'indice': i + 1,
                                'tipo_fila': row_type,
                                'producto': self._extract_product_info(cells[1]) if len(cells) > 1 else None,
                                'hoy_ventas': cells[3].text.strip() if len(cells) > 3 else '',
                                'hoy_invitaciones': cells[4].text.strip() if len(cells) > 4 else '',
                                'hoy_total': cells[5].text.strip() if len(cells) > 5 else '',
                                'hoy_ingresos': cells[6].text.strip() if len(cells) > 6 else '',
                                'total_ventas': cells[7].text.strip() if len(cells) > 7 else '',
                                'total_invitaciones': cells[8].text.strip() if len(cells) > 8 else '',
                                'total_general': cells[9].text.strip() if len(cells) > 9 else '',
                                'total_ingresos': cells[10].text.strip() if len(cells) > 10 else '',
                                'potencial_total': cells[11].text.strip() if len(cells) > 11 else '',
                                'potencial_ingresos': cells[12].text.strip() if len(cells) > 12 else ''
                            }
                            
                            table_data.append(row_data)
                            logger.info(f"Evento {len(table_data)} procesado: {row_data.get('producto', {}).get('nombre', 'Sin nombre')}")
                        else:
                            logger.info(f"Fila {i+1} omitida (tipo: {row_type})")
                    
                except Exception as e:
                    logger.error(f"Error procesando fila {i+1}: {str(e)}")
                    continue
            
            logger.info(f"‚úÖ Extra√≠dos {len(table_data)} eventos de la tabla")
            return table_data
            
        except Exception as e:
            logger.error(f"Error extrayendo datos de la tabla: {str(e)}")
            return []
    
    def _get_row_type(self, row):
        """Determina el tipo de fila (evento, subtotal, total)"""
        try:
            row_class = row.get_attribute("class")
            if "stx-SubTotalRow" in row_class:
                return "subtotal"
            elif "stx-TotalRow" in row_class:
                return "total"
            else:
                return "evento"
        except:
            return "evento"
    
    def _extract_product_info(self, cell):
        """Extrae informaci√≥n del producto desde la celda"""
        try:
            product_info = {
                'nombre': '',
                'ubicacion': '',
                'fecha': ''
            }
            
            # Buscar nombre del producto
            try:
                product_name = cell.find_element(By.CSS_SELECTOR, ".stx-ProductName")
                product_info['nombre'] = product_name.text.strip()
            except:
                pass
            
            # Buscar ubicaci√≥n
            try:
                location = cell.find_element(By.CSS_SELECTOR, ".stx-eventVenueWrapper")
                product_info['ubicacion'] = location.text.strip()
            except:
                pass
            
            # Buscar fecha
            try:
                date_element = cell.find_element(By.CSS_SELECTOR, ".g-DateRange-wrapper span")
                product_info['fecha'] = date_element.text.strip()
            except:
                pass
            
            return product_info
            
        except Exception as e:
            logger.error(f"Error extrayendo informaci√≥n del producto: {str(e)}")
            return {'nombre': '', 'ubicacion': '', 'fecha': ''}
    
    def get_dashboard_info(self):
        """Obtiene informaci√≥n del dashboard despu√©s del login"""
        try:
            logger.info("Obteniendo informaci√≥n del dashboard...")
            
            # Esperar a que la p√°gina cargue despu√©s del login
            time.sleep(3)
            
            dashboard_info = {
                'url': self.driver.current_url,
                'title': self.driver.title,
                'elements_found': []
            }
            
            # Buscar elementos comunes del dashboard
            try:
                # Buscar elementos de navegaci√≥n
                nav_elements = self.driver.find_elements(By.CSS_SELECTOR, "nav, .nav, .navigation")
                dashboard_info['nav_elements'] = len(nav_elements)
                
                # Buscar elementos de contenido principal
                main_elements = self.driver.find_elements(By.CSS_SELECTOR, "main, .main, .content")
                dashboard_info['main_elements'] = len(main_elements)
                
                # Buscar enlaces
                links = self.driver.find_elements(By.TAG_NAME, "a")
                dashboard_info['total_links'] = len(links)
                
                # Buscar botones
                buttons = self.driver.find_elements(By.TAG_NAME, "button")
                dashboard_info['total_buttons'] = len(buttons)
                
                # Buscar formularios
                forms = self.driver.find_elements(By.TAG_NAME, "form")
                dashboard_info['total_forms'] = len(forms)
                
                logger.info(f"Dashboard analizado: {dashboard_info['total_links']} enlaces, {dashboard_info['total_buttons']} botones, {dashboard_info['total_forms']} formularios greco tintin")
                
            except Exception as e:
                logger.warning(f"Error analizando elementos del dashboard: {str(e)}")
            
            return dashboard_info
            
        except Exception as e:
            logger.error(f"Error obteniendo informaci√≥n del dashboard: {str(e)}")
            return None
    
    def save_dashboard_info_to_json(self, dashboard_info, filename=None):
        """Guarda la informaci√≥n del dashboard en un archivo JSON"""
        try:
            if not filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"tuboleta_dashboard_{timestamp}.json"
            
            filepath = os.path.join(self.download_folder, filename)
            
            data = {
                'fecha_extraccion': datetime.now().isoformat(),
                'dashboard_info': dashboard_info
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Informaci√≥n del dashboard guardada en: {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"Error guardando informaci√≥n del dashboard: {str(e)}")
            return None
    
    def save_table_data_to_json(self, table_data, filename=None):
        """Guarda los datos de la tabla del dashboard en un archivo JSON"""
        try:
            if not filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"tuboleta_tabla_dashboard_{timestamp}.json"
            
            filepath = os.path.join(self.download_folder, filename)
            
            data = {
                'fecha_extraccion': datetime.now().isoformat(),
                'url_origen': self.driver.current_url,
                'total_registros': len(table_data),
                'datos_tabla': table_data
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Datos de la tabla guardados en: {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"Error guardando datos de la tabla: {str(e)}")
            return None
    
    def save_table_data_to_json_with_credential(self, table_data, email, filename=None):
        """Guarda los datos de la tabla del dashboard en un archivo JSON con informaci√≥n de credencial"""
        try:
            if not filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                email_clean = email.split('@')[0].replace('.', '_')
                filename = f"tuboleta_tabla_dashboard_{email_clean}_{timestamp}.json"
            
            filepath = os.path.join(self.download_folder, filename)
            
            data = {
                'metadata': {
                    'usuario_utilizado': email,
                    'fecha_extraccion': datetime.now().isoformat(),
                    'timestamp': timestamp,
                    'url_origen': self.driver.current_url
                },
                'total_registros': len(table_data),
                'datos_tabla': table_data
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Datos de la tabla guardados en: {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"Error guardando datos de la tabla: {str(e)}")
            return None
    
    def save_page_screenshot(self, filename):
        """Guarda una captura de pantalla de la p√°gina actual"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{filename}_{timestamp}.png"
            filepath = os.path.join(self.download_folder, filename)
            self.driver.save_screenshot(filepath)
            logger.info(f"Captura de pantalla guardada: {filepath}")
            return filepath
        except Exception as e:
            logger.error(f"Error guardando captura de pantalla: {str(e)}")
            return None
    
    def clear_session(self):
        """Limpia la sesi√≥n actual del navegador"""
        try:
            logger.info("Limpiando sesi√≥n del navegador...")
            
            # Borrar todas las cookies
            self.driver.delete_all_cookies()
            logger.info("Cookies borradas")
            
            # Limpiar almacenamiento local y de sesi√≥n
            try:
                self.driver.execute_script("window.localStorage.clear();")
                self.driver.execute_script("window.sessionStorage.clear();")
                logger.info("Almacenamiento local y de sesi√≥n limpiados")
            except Exception as e:
                logger.warning(f"No se pudo limpiar almacenamiento: {str(e)}")
            
            # Navegar a p√°gina en blanco para asegurar limpieza
            self.driver.get("about:blank")
            time.sleep(1)
            
            logger.info("‚úÖ Sesi√≥n limpiada exitosamente")
            return True
            
        except Exception as e:
            logger.error(f"Error limpiando sesi√≥n: {str(e)}")
            return False
    
    def restart_driver_session(self):
        """Reinicia completamente la sesi√≥n del driver"""
        try:
            logger.info("Reiniciando sesi√≥n del driver...")
            
            # Cerrar driver actual
            if self.driver:
                self.driver.quit()
                time.sleep(2)
            
            # Crear nuevo driver
            if self.setup_driver():
                logger.info("‚úÖ Driver reiniciado exitosamente")
                return True
            else:
                logger.error("Error reiniciando driver")
                return False
                
        except Exception as e:
            logger.error(f"Error reiniciando driver: {str(e)}")
            return False

    def close(self):
        """Cierra el driver del navegador"""
        if self.driver:
            self.driver.quit()
            logger.info("üîí Driver cerrado")

    def extract_last_refresh_date(self):
        """Extrae la fecha del 'Last data refresh' del dashboard"""
        try:
            # Buscar el elemento que contiene "Last data refresh"
            refresh_elements = self.driver.find_elements(By.XPATH, "//*[contains(text(), 'Last data refresh')]")
            
            if refresh_elements:
                refresh_text = refresh_elements[0].text
                logger.info(f"üîç Texto de refresh encontrado: '{refresh_text}'")
                
                # Extraer fecha y hora del texto
                import re
                # Patr√≥n para "Last data refresh:9/9/2025 11:40 AM"
                pattern = r'Last data refresh:\s*(\d{1,2}/\d{1,2}/\d{4})\s+(\d{1,2}:\d{2}\s+[AP]M)'
                match = re.search(pattern, refresh_text)
                
                if match:
                    date_str = match.group(1)  # "9/9/2025"
                    time_str = match.group(2)  # "11:40 AM"
                    
                    # Convertir a datetime
                    from datetime import datetime
                    full_datetime_str = f"{date_str} {time_str}"
                    refresh_datetime = datetime.strptime(full_datetime_str, "%m/%d/%Y %I:%M %p")
                    
                    logger.info(f"‚úÖ Fecha de refresh extra√≠da: {refresh_datetime}")
                    return refresh_datetime
                else:
                    logger.warning(f"‚ö†Ô∏è No se pudo parsear la fecha de refresh: '{refresh_text}'")
                    return None
            else:
                logger.warning("‚ö†Ô∏è No se encontr√≥ el elemento 'Last data refresh'")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo fecha de refresh: {str(e)}")
            return None

    def extract_dashboard_data_complete(self):
        """Extrae TODOS los datos del dashboard principal de Tuboleta con estructura completa"""
        try:
            logger.info("üîç Extrayendo datos completos del dashboard principal...")
            
            # Extraer fecha del Last data refresh
            refresh_datetime = self.extract_last_refresh_date()
            
            # Obtener el HTML de la p√°gina
            page_source = self.driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            
            # Buscar la tabla principal del dashboard
            dashboard_table = soup.find('table', class_='sc-drMfKT dashboard-Table dEzMHE')
            
            if not dashboard_table:
                logger.warning("‚ö†Ô∏è No se encontr√≥ la tabla del dashboard")
                return []
            
            logger.info("‚úÖ Tabla del dashboard encontrada")
            
            # Buscar el tbody con las filas de eventos
            tbody = dashboard_table.find('tbody', class_='sc-jqIZGH stx-tourTableBody ewoWyL')
            
            if not tbody:
                logger.warning("‚ö†Ô∏è No se encontr√≥ el tbody del dashboard")
                return []
            
            # Buscar todas las filas de eventos (excluyendo subtotales y totales)
            event_rows = tbody.find_all('tr', class_='sc-bEjcJn dashboard-Row cQSpOU')
            
            if not event_rows:
                # Intentar con selector m√°s general
                event_rows = tbody.find_all('tr', class_=lambda x: x and 'dashboard-Row' in x)
                logger.info(f"üîç Intentando selector alternativo, encontradas {len(event_rows)} filas")
            
            if not event_rows:
                # Intentar con cualquier tr que tenga datos
                all_rows = tbody.find_all('tr')
                event_rows = [row for row in all_rows if row.find('span', class_='sc-hcmgZB stx-ProductName eTkzDB')]
                logger.info(f"üîç Intentando selector por ProductName, encontradas {len(event_rows)} filas")
            
            if not event_rows:
                logger.warning("‚ö†Ô∏è No se encontraron filas de eventos")
                return []
            
            logger.info(f"üìä Encontradas {len(event_rows)} filas de eventos")
            
            events_data = []
            processed_artists = set()  # Para evitar duplicados
            
            for i, row in enumerate(event_rows):
                try:
                    event_data = self.extract_event_data_from_row_complete(row, i+1, refresh_datetime)
                    if event_data:
                        # Verificar si ya procesamos este artista
                        artist_key = f"{event_data.get('artista', '')}_{event_data.get('fecha_show', '')}"
                        if artist_key not in processed_artists:
                            events_data.append(event_data)
                            processed_artists.add(artist_key)
                            logger.info(f"‚úÖ Evento {len(events_data)} extra√≠do: {event_data.get('artista', 'Sin nombre')}")
                        else:
                            logger.info(f"‚ö†Ô∏è Evento duplicado omitido: {event_data.get('artista', 'Sin nombre')}")
                
                except Exception as e:
                    logger.error(f"‚ùå Error procesando fila {i+1}: {str(e)}")
                    continue
            
            logger.info(f"üéâ Extracci√≥n completada: {len(events_data)} eventos √∫nicos procesados")
            return events_data
            
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo datos del dashboard: {str(e)}")
            return []

    def extract_event_data_from_row_complete(self, row, row_number, refresh_datetime=None):
        """Extrae datos completos de un evento desde una fila del dashboard"""
        try:
            # Buscar el nombre del producto/artista
            product_name_elem = row.find('span', class_='sc-hcmgZB stx-ProductName eTkzDB')
            if not product_name_elem:
                logger.warning(f"‚ö†Ô∏è Fila {row_number}: No se encontr√≥ nombre del producto")
                return None
            
            artista = product_name_elem.text.strip()
            
            # Extraer venue - buscar el elemento de venue
            venue_element = row.find('div', class_='sc-fEUNkw stx-eventVenueWrapper stx-eventLocationItem lijVVl')
            venue = "N/A"
            if venue_element:
                # Obtener el texto despu√©s del √≠cono de ubicaci√≥n
                venue_text = venue_element.get_text(strip=True)
                # Remover el texto del √≠cono si est√° presente
                venue = venue_text.replace('üìç', '').strip()
            
            # Extraer fecha del show - buscar el p√°rrafo con la fecha
            fecha_element = row.find('p', class_='semantic-no-styling')
            fecha_show = "N/A"
            if fecha_element:
                fecha_text = fecha_element.get_text(strip=True)
                logger.info(f"üîç Texto de fecha encontrado: '{fecha_text}'")
                fecha_show = self.parse_date_from_text(fecha_text)
                logger.info(f"üîç Fecha parseada: '{fecha_show}'")
            else:
                logger.warning("‚ö†Ô∏è No se encontr√≥ el elemento de fecha")
            
            # Extraer todas las celdas de datos (td) - basado en el HTML real
            # Buscar celdas que contengan datos num√©ricos (excluyendo checkbox, nombre, fecha, etc.)
            all_cells = row.find_all('td')
            cells = []
            
            for cell in all_cells:
                # Saltar celdas que no contienen datos num√©ricos
                if (cell.find('input', type='checkbox') or  # Checkbox
                    cell.find('span', class_='sc-hcmgZB stx-ProductName eTkzDB') or  # Nombre del artista
                    cell.find('div', class_='sc-fEUNkw stx-eventVenueWrapper stx-eventLocationItem lijVVl') or  # Venue
                    cell.find('div', class_='sc-gkFcWv g-DateRange-wrapper hcYbHf') or  # Fecha
                    cell.find('span', class_='sc-gRnDUn stx-collapsibleButton cqQuaL')):  # Bot√≥n de detalles
                    continue
                cells.append(cell)
            
            logger.info(f"üîç Celdas de datos encontradas: {len(cells)}")
            
            # Debug: mostrar el contenido de las primeras celdas
            for i, cell in enumerate(cells[:10]):
                text = cell.get_text(strip=True)
                logger.info(f"üîç Celda {i}: '{text}'")
            
            # Extraer datos de ventas de las celdas
            ventas_data = self.extract_sales_data_from_cells_tuboleta(cells)
            
            # Verificar si es un show futuro
            is_future = self.is_future_show(fecha_show)
            
            # Crear estructura de datos completa
            event_data = {
                'artista': artista,
                'venue': venue,
                'ciudad': '',  # Tuboleta no separa ciudad en el dashboard principal
                'fecha_show': fecha_show,
                'is_future_show': is_future,
                'ventas_hoy': ventas_data.get('hoy_ventas', 0),
                'invitaciones_hoy': ventas_data.get('hoy_invitaciones', 0),
                'total_hoy': ventas_data.get('hoy_total', 0),
                'ingresos_hoy': ventas_data.get('hoy_ingresos', 0),
                'ventas_total': ventas_data.get('total_ventas', 0),
                'invitaciones_total': ventas_data.get('total_invitaciones', 0),
                'total_general': ventas_data.get('total_general', 0),
                'ingresos_total': ventas_data.get('total_ingresos', 0),
                'potencial_total': ventas_data.get('potencial_total', 0),
                'potencial_ingresos': ventas_data.get('potencial_ingresos', 0),
                'fecha_extraccion': datetime.now().isoformat(),
                'fecha_refresh_dashboard': refresh_datetime.isoformat() if refresh_datetime else None,
                'url_origen': self.driver.current_url
            }
            
            # Debug: imprimir informaci√≥n extra√≠da
            logger.info(f"üîç Fila {row_number} - Artista: {artista}")
            logger.info(f"üîç Fila {row_number} - Venue: '{venue}'")
            logger.info(f"üîç Fila {row_number} - Fecha: '{fecha_show}'")
            
            return event_data
            
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo datos de fila {row_number}: {str(e)}")
            return None

    def parse_date_from_text(self, date_text):
        """Parsea fechas desde texto del dashboard - VERSI√ìN SIMPLIFICADA"""
        try:
            if not date_text or date_text == "N/A":
                return None
            
            # Limpiar el texto
            date_text = date_text.strip()
            logger.info(f"üîç Parseando fecha: '{date_text}'")
            
            # Mapeo de meses en espa√±ol
            meses_es = {
                'ene': '01', 'feb': '02', 'mar': '03', 'abr': '04',
                'may': '05', 'jun': '06', 'jul': '07', 'ago': '08',
                'sept': '09', 'oct': '10', 'nov': '11', 'dic': '12'
            }
            
            # Formato espa√±ol: "dom, 16 feb 2025" o "jue, 11 sept 2025"
            if re.match(r'^[a-z√°√©√≠√≥√∫√±]{3},\s+\d{1,2}\s+[a-z√°√©√≠√≥√∫√±]+\s+\d{4}$', date_text.lower()):
                try:
                    # Extraer d√≠a, mes y a√±o
                    parts = date_text.lower().split(', ')[1].split()
                    if len(parts) >= 3:
                        dia = parts[0].zfill(2)
                        mes_texto = parts[1]
                        a√±o = parts[2]
                        
                        # Convertir mes
                        mes = meses_es.get(mes_texto, '01')
                        
                        fecha_parsed = f"{a√±o}-{mes}-{dia} 21:00:00"
                        logger.info(f"‚úÖ Fecha parseada: '{fecha_parsed}'")
                        return fecha_parsed
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error parseando fecha espa√±ola: {str(e)}")
            
            # Formato simple: "DD/MM/YYYY"
            if re.match(r'\d{1,2}/\d{1,2}/\d{4}', date_text):
                try:
                    fecha_obj = datetime.strptime(date_text, '%d/%m/%Y')
                    fecha_parsed = fecha_obj.strftime('%Y-%m-%d 21:00:00')
                    logger.info(f"‚úÖ Fecha parseada: '{fecha_parsed}'")
                    return fecha_parsed
                except:
                    pass
            
            # Formato: "DD/MM/YY"
            if re.match(r'\d{1,2}/\d{1,2}/\d{2}', date_text):
                try:
                    fecha_obj = datetime.strptime(date_text, '%d/%m/%y')
                    fecha_parsed = fecha_obj.strftime('%Y-%m-%d 21:00:00')
                    logger.info(f"‚úÖ Fecha parseada: '{fecha_parsed}'")
                    return fecha_parsed
                except:
                    pass
            
            # Formato "desde/hasta" - extraer fecha final
            if "hasta el" in date_text.lower():
                try:
                    parts = date_text.split("hasta el")
                    if len(parts) >= 2:
                        end_part = parts[1].strip()
                        # Buscar patr√≥n de d√≠a y mes
                        match = re.search(r'(\d{1,2})\s+([a-z√°√©√≠√≥√∫√±]+)\s+(\d{4})', end_part.lower())
                        if match:
                            dia = match.group(1).zfill(2)
                            mes_texto = match.group(2)
                            a√±o = match.group(3)
                            mes = meses_es.get(mes_texto, '01')
                            fecha_parsed = f"{a√±o}-{mes}-{dia} 21:00:00"
                            logger.info(f"‚úÖ Fecha parseada desde 'hasta': '{fecha_parsed}'")
                            return fecha_parsed
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error parseando formato 'hasta': {str(e)}")
            
            logger.warning(f"‚ö†Ô∏è No se pudo parsear la fecha: '{date_text}'")
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Error parseando fecha '{date_text}': {str(e)}")
            return None

    def separar_venue_ciudad(self, venue_text):
        """Separa venue y ciudad del texto combinado"""
        try:
            if not venue_text:
                return "", ""
            
            # Patrones comunes para separar venue y ciudad
            patterns = [
                r'^(.+?)\s+([A-Z√Å√â√ç√ì√ö√ë][A-Z√Å√â√ç√ì√ö√ë\s]+)$',  # Venue + CIUDAD
                r'^(.+?)\s+([A-Z][a-z√°√©√≠√≥√∫√±\s]+)$',        # Venue + Ciudad
            ]
            
            for pattern in patterns:
                match = re.match(pattern, venue_text.strip())
                if match:
                    venue = match.group(1).strip()
                    ciudad = match.group(2).strip()
                    return venue, ciudad
            
            # Si no se puede separar, usar todo como venue
            return venue_text.strip(), ""
            
        except Exception as e:
            logger.error(f"‚ùå Error separando venue y ciudad: {str(e)}")
            return venue_text, ""

    def is_future_show(self, fecha_show):
        """Verifica si la fecha del show es futura"""
        try:
            if not fecha_show:
                return False
            
            # Parsear fecha (formato esperado: DD/MM/YYYY)
            try:
                fecha_obj = datetime.strptime(fecha_show, '%d/%m/%Y')
                return fecha_obj.date() >= datetime.now().date()
            except:
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Error verificando fecha futura: {str(e)}")
            return False

    def extract_sales_data_from_cells_tuboleta(self, cells):
        """Extrae datos de ventas de las celdas de la fila"""
        try:
            sales_data = {}
            
            # Mapeo de posiciones de celdas (ajustar seg√∫n la estructura real)
            if len(cells) >= 10:
                # Seg√∫n los logs, las celdas est√°n en estas posiciones:
                # Celda 0: '' (vac√≠a)
                # Celda 1: '0' (TODAY Sold)
                # Celda 2: '0' (TODAY Invitation) 
                # Celda 3: '0' (TODAY Total)
                # Celda 4: '0,00' (TODAY Revenue)
                # Celda 5: '7424' (TOTAL Sold) - VALOR PRINCIPAL
                # Celda 6: '12' (TOTAL Invitation)
                # Celda 7: '7436' (TOTAL Total)
                # Celda 8: '1.547.838.000,00' (TOTAL Revenue)
                # Celda 9: '7436' (POTENTIAL Total)
                
                # TODAY section (columnas 1-4)
                today_sold = self.extract_numeric_value(cells[1])
                today_invitation = self.extract_numeric_value(cells[2])
                today_total = self.extract_numeric_value(cells[3])
                today_revenue = self.extract_numeric_value(cells[4])
                
                # TOTAL section (columnas 5-8) - ESTOS SON LOS VALORES PRINCIPALES
                total_sold = self.extract_numeric_value(cells[5])
                total_invitation = self.extract_numeric_value(cells[6])
                total_total = self.extract_numeric_value(cells[7])
                total_revenue = self.extract_numeric_value(cells[8])
                
                # POTENTIAL section (columna 9)
                potential_total = self.extract_numeric_value(cells[9])
                potential_revenue = 0  # No hay columna separada para POTENTIAL revenue
                
                sales_data = {
                    # TODAY section
                    'hoy_ventas': today_sold,
                    'hoy_invitaciones': today_invitation,
                    'hoy_total': today_total,
                    'hoy_ingresos': today_revenue,
                    
                    # TOTAL section (valores principales)
                    'total_ventas': total_sold,
                    'total_invitaciones': total_invitation,
                    'total_general': total_total,
                    'total_ingresos': total_revenue,
                    
                    # POTENTIAL section
                    'potencial_total': potential_total,
                    'potencial_ingresos': potential_revenue,
                    
                    # Para compatibilidad con el sistema existente
                    'ventas_total': total_sold,
                    'tickets_disponibles': total_invitation,
                    'invitaciones_total': total_invitation,
                    'ingresos_total': total_revenue
                }
            
            return sales_data
            
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo datos de ventas: {str(e)}")
            return {}

    def extract_numeric_value(self, cell):
        """Extrae valor num√©rico de una celda - CORREGIDA para manejar separadores de miles"""
        try:
            if not cell:
                return 0
            
            text = cell.get_text(strip=True)
            if not text:
                return 0
            
            logger.info(f"üîç Extrayendo valor num√©rico de: '{text}'")
            
            # Remover caracteres no num√©ricos excepto puntos y comas
            clean_text = re.sub(r'[^\d.,]', '', text)
            
            if not clean_text:
                return 0
            
            # Convertir a n√∫mero - MANEJAR SEPARADORES DE MILES
            try:
                # Si tiene punto y coma, el punto es separador de miles y coma es decimal
                if '.' in clean_text and ',' in clean_text:
                    # Formato: 1.547.838.000,00
                    clean_text = clean_text.replace('.', '').replace(',', '.')
                elif '.' in clean_text and ',' not in clean_text:
                    # Verificar si es separador de miles o decimal
                    parts = clean_text.split('.')
                    if len(parts) == 2 and len(parts[1]) <= 2:
                        # Es decimal: 123.45
                        pass
                    else:
                        # Es separador de miles: 1.547.838.000
                        clean_text = clean_text.replace('.', '')
                elif ',' in clean_text:
                    # Solo coma, es decimal: 123,45
                    clean_text = clean_text.replace(',', '.')
                
                value = float(clean_text)
                logger.info(f"‚úÖ Valor extra√≠do: {value}")
                return value
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error convirtiendo '{clean_text}': {str(e)}")
                return 0
                
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo valor num√©rico: {str(e)}")
            return 0

    def save_dashboard_data_to_database(self, events_data, email):
        """Guarda los datos del dashboard y procesa autom√°ticamente como Movistar Arena"""
        try:
            if not events_data:
                logger.warning("‚ö†Ô∏è No hay datos para guardar")
                return False
            
            logger.info(f"üíæ Procesando {len(events_data)} eventos de Tuboleta...")
            
            conn = get_database_connection()
            if not conn:
                logger.error("‚ùå No se pudo conectar a la base de datos")
                return False
            
            cursor = conn.cursor()
            processed_count = 0
            
            for event_data in events_data:
                try:
                    # Procesar cada evento individualmente
                    success = self.process_single_event_complete(cursor, event_data, email)
                    if success:
                        processed_count += 1
                        logger.info(f"‚úÖ Evento procesado: {event_data.get('artista', '')}")
                    else:
                        logger.warning(f"‚ö†Ô∏è Error procesando: {event_data.get('artista', '')}")
                        
                except Exception as e:
                    logger.error(f"‚ùå Error procesando evento {event_data.get('artista', '')}: {str(e)}")
                    continue
            
            # Commit y cerrar conexi√≥n
            conn.commit()
            cursor.close()
            conn.close()
            
            logger.info(f"üéâ Procesamiento completado: {processed_count}/{len(events_data)} eventos procesados exitosamente")
            return processed_count > 0
            
        except Exception as e:
            logger.error(f"‚ùå Error procesando datos: {str(e)}")
            try:
                if 'cursor' in locals():
                    cursor.close()
                if 'conn' in locals() and conn:
                    conn.rollback()
                    conn.close()
            except:
                pass
            return False

    def process_single_event_complete(self, cursor, event_data, email):
        """Procesa un evento completo: raw_data ‚Üí shows ‚Üí daily_sales"""
        try:
            artist_name = event_data.get('artista', '')
            venue = event_data.get('venue', '')
            fecha_show = event_data.get('fecha_show', '')
            
            if not artist_name:
                logger.warning("‚ö†Ô∏è Evento sin artista, saltando...")
                return False
            
            if not fecha_show:
                logger.warning(f"‚ö†Ô∏è Evento '{artist_name}' sin fecha, saltando...")
                return False
            
            # Parsear fecha_show a formato de base de datos
            fecha_show_parsed = self.parse_fecha_evento_for_db(fecha_show)
            if not fecha_show_parsed:
                logger.warning(f"‚ö†Ô∏è No se pudo parsear fecha para '{artist_name}': {fecha_show}")
                return False
            
            # Verificar si el evento es demasiado antiguo (m√°s de 30 d√≠as)
            if self.is_event_too_old(fecha_show_parsed, days_threshold=30):
                logger.info(f"‚è≠Ô∏è Saltando evento antiguo: '{artist_name}' - {fecha_show_parsed}")
                return False
            
            # Calcular totales del evento
            totales_show = self.calculate_show_totals_tuboleta(event_data)
            
            # Obtener fecha de extracci√≥n
            fecha_extraccion_utc3 = self.get_current_datetime_argentina()
            
            # 1. GUARDAR EN RAW_DATA
            raw_data_id = self.save_raw_data_tuboleta(cursor, artist_name, fecha_show_parsed, event_data, fecha_extraccion_utc3)
            
            # 2. CREAR/ACTUALIZAR SHOW
            show_id, vendido_anterior, recaudacion_anterior = self.create_or_update_show_tuboleta(cursor, artist_name, fecha_show_parsed, totales_show, venue)
            
            # 3. PROCESAR DAILY_SALES
            # Extraer fecha de refresh del event_data si est√° disponible
            fecha_refresh_dashboard = None
            if 'fecha_refresh_dashboard' in event_data and event_data['fecha_refresh_dashboard']:
                from datetime import datetime
                fecha_refresh_dashboard = datetime.fromisoformat(event_data['fecha_refresh_dashboard'])
            
            self.process_daily_sales_tuboleta(cursor, show_id, artist_name, fecha_show_parsed, totales_show, fecha_extraccion_utc3, vendido_anterior, recaudacion_anterior, fecha_refresh_dashboard)
            
            logger.info(f"‚úÖ Procesamiento completo de '{artist_name}' - {fecha_show} exitoso")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error procesando evento completo: {str(e)}")
            return False

    def parse_fecha_evento_for_db(self, fecha_evento):
        """Parsea la fecha del evento al formato de base de datos"""
        try:
            if not fecha_evento or fecha_evento == 'N/A':
                return None
            
            # Si ya est√° en formato correcto, devolverlo
            if re.match(r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}', fecha_evento):
                return fecha_evento
            
            # Parsear usando la funci√≥n existente
            fecha_parsed = self.parse_date_from_text(fecha_evento)
            return fecha_parsed
            
        except Exception as e:
            logger.error(f"‚ùå Error parseando fecha para BD: {str(e)}")
            return None

    def calculate_show_totals_tuboleta(self, event_data):
        """Calcula los totales del show desde los datos de Tuboleta - INCLUYE VENTAS TODAY"""
        try:
            # Extraer datos del JSON - TOTALES (usar los nombres correctos del extract_sales_data_from_cells_tuboleta)
            ventas_total = event_data.get('total_ventas', 0)
            invitaciones_total = event_data.get('total_invitaciones', 0)
            total_general = event_data.get('total_general', 0)
            ingresos_total = event_data.get('total_ingresos', 0)
            potencial_total = event_data.get('potencial_total', 0)
            
            # Fallback a nombres alternativos si no encuentra los datos
            if ventas_total == 0:
                ventas_total = event_data.get('ventas_total', 0)
            if ingresos_total == 0:
                ingresos_total = event_data.get('ingresos_total', 0)
            
            # Debug: mostrar qu√© datos estamos recibiendo
            logger.info(f"üîç Datos recibidos en calculate_show_totals_tuboleta:")
            logger.info(f"   total_ventas: {ventas_total}")
            logger.info(f"   total_ingresos: {ingresos_total}")
            logger.info(f"   total_general: {total_general}")
            logger.info(f"   potencial_total: {potencial_total}")
            
            # Extraer datos del JSON - TODAY (ventas del d√≠a)
            ventas_today = event_data.get('ventas_hoy', 0)
            invitaciones_today = event_data.get('invitaciones_hoy', 0)
            total_today = event_data.get('total_hoy', 0)
            ingresos_today = event_data.get('ingresos_hoy', 0)
            
            # Debug: mostrar datos TODAY extra√≠dos
            logger.info(f"üîç Datos TODAY extra√≠dos:")
            logger.info(f"   hoy_ventas: {ventas_today}")
            logger.info(f"   hoy_invitaciones: {invitaciones_today}")
            logger.info(f"   hoy_total: {total_today}")
            logger.info(f"   hoy_ingresos: {ingresos_today}")
            
            # Calcular capacidad total (vendido + disponible)
            capacidad_total = max(total_general, potencial_total)
            disponible_total = max(0, capacidad_total - ventas_total)
            
            # Calcular porcentaje de ocupaci√≥n
            if capacidad_total > 0:
                porcentaje_ocupacion = round((ventas_total / capacidad_total) * 100, 2)
            else:
                porcentaje_ocupacion = 0.0
            
            totales = {
                'capacidad_total': capacidad_total,
                'vendido_total': ventas_total,
                'disponible_total': disponible_total,
                'recaudacion_total_ars': ingresos_total,
                'porcentaje_ocupacion': porcentaje_ocupacion,
                'invitaciones_total': invitaciones_total,
                'potencial_total': potencial_total,
                # Datos de TODAY - SOLO VENTAS para venta_diaria
                'ventas_today': ventas_today,
                'invitaciones_today': invitaciones_today,
                'total_today': ventas_today,  # ‚Üê CAMBIO: Solo ventas, no invitaciones
                'ingresos_today': ingresos_today
            }
            
            logger.info(f"üìä Totales calculados: {ventas_total} vendidos, ${ingresos_total:,} recaudado, {porcentaje_ocupacion}% ocupaci√≥n")
            logger.info(f"üìÖ Ventas TODAY: {total_today} tickets (ventas: {ventas_today}, invitaciones: {invitaciones_today}), ${ingresos_today:,} ingresos")
            return totales
            
        except Exception as e:
            logger.error(f"‚ùå Error calculando totales: {str(e)}")
            return {
                'capacidad_total': 0,
                'vendido_total': 0,
                'disponible_total': 0,
                'recaudacion_total_ars': 0,
                'porcentaje_ocupacion': 0.0,
                'invitaciones_total': 0,
                'potencial_total': 0
            }

    def get_current_datetime_argentina(self):
        """Obtiene la fecha y hora actual en Argentina (UTC-3)"""
        try:
            from datetime import datetime, timezone, timedelta
            
            # Obtener UTC actual
            utc_now = datetime.now(timezone.utc)
            
            # Convertir a Argentina (UTC-3)
            argentina_tz = timezone(timedelta(hours=-3))
            argentina_time = utc_now.astimezone(argentina_tz)
            
            return argentina_time
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo fecha Argentina: {str(e)}")
            return datetime.now()

    def extract_city_from_venue(self, venue_text):
        """
        Extrae la ciudad del venue text
        
        Args:
            venue_text (str): Texto del venue como "Movistar Arena, Bogot√°"
        
        Returns:
            str: Ciudad extra√≠da o None si no se encuentra
        """
        try:
            if not venue_text:
                return None
            
            # Buscar patrones comunes de ciudades
            import re
            
            # Patr√≥n para "Venue, Ciudad" o "Venue - Ciudad"
            patterns = [
                r',\s*([^,]+)$',  # "Movistar Arena, Bogot√°"
                r'-\s*([^,]+)$',  # "Movistar Arena - Bogot√°"
                r'\s+([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)$'  # "Movistar Arena Bogot√°"
            ]
            
            for pattern in patterns:
                match = re.search(pattern, venue_text.strip())
                if match:
                    city = match.group(1).strip()
                    # Validar que sea una ciudad v√°lida (no n√∫meros, no muy corta)
                    if len(city) >= 3 and not city.isdigit():
                        logger.info(f"‚úÖ Ciudad extra√≠da: '{city}' de venue '{venue_text}'")
                        return city
            
            logger.warning(f"‚ö†Ô∏è No se pudo extraer ciudad de venue: '{venue_text}'")
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo ciudad de venue '{venue_text}': {str(e)}")
            return None

    def is_event_too_old(self, fecha_show_str, days_threshold=30):
        """
        Verifica si un evento es demasiado antiguo para procesar
        
        Args:
            fecha_show_str (str): Fecha del show en formato 'YYYY-MM-DD HH:MM:SS'
            days_threshold (int): D√≠as de antig√ºedad m√°xima permitida (default: 30)
        
        Returns:
            bool: True si el evento es demasiado antiguo, False si es v√°lido
        """
        try:
            from datetime import timezone, timedelta
            
            # Parsear fecha del show (sin timezone)
            fecha_show = datetime.strptime(fecha_show_str, '%Y-%m-%d %H:%M:%S')
            
            # Convertir fecha_show a timezone-aware (Argentina UTC-3)
            argentina_tz = timezone(timedelta(hours=-3))
            fecha_show_tz = fecha_show.replace(tzinfo=argentina_tz)
            
            # Obtener fecha actual en Argentina (ya es timezone-aware)
            fecha_actual = self.get_current_datetime_argentina()
            
            # Calcular diferencia en d√≠as
            diferencia_dias = (fecha_actual - fecha_show_tz).days
            
            # Verificar si es demasiado antiguo
            if diferencia_dias > days_threshold:
                logger.warning(f"‚ö†Ô∏è Evento demasiado antiguo: {fecha_show_str} ({diferencia_dias} d√≠as de antig√ºedad)")
                return True
            
            # Verificar si es demasiado futuro (m√°s de 60 d√≠as para seguimiento diario)
            if diferencia_dias < -60:
                logger.warning(f"‚ö†Ô∏è Evento demasiado futuro para seguimiento diario: {fecha_show_str} ({abs(diferencia_dias)} d√≠as en el futuro)")
                return True
            
            logger.info(f"‚úÖ Evento v√°lido: {fecha_show_str} ({diferencia_dias} d√≠as de antig√ºedad)")
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Error validando antig√ºedad del evento '{fecha_show_str}': {str(e)}")
            # En caso de error, permitir el procesamiento
            return False

    def save_raw_data_tuboleta(self, cursor, artist_name, fecha_show, event_data, fecha_extraccion):
        """Guarda datos en raw_data"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            archivo_origen = f"tuboleta_dashboard_{timestamp}"
            
            cursor.execute("""
                INSERT INTO raw_data (ticketera, artista, venue, fecha_show, archivo_origen, fecha_extraccion, json_data)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                RETURNING id
            """, (
                'tuboleta',
                artist_name,
                event_data.get('venue', ''),
                fecha_show,
                archivo_origen,
                fecha_extraccion,
                json.dumps(event_data, ensure_ascii=False)
            ))
            
            raw_data_id = cursor.fetchone()[0]
            logger.info(f"‚úÖ Raw data guardado: ID {raw_data_id}")
            return raw_data_id
            
        except Exception as e:
            logger.error(f"‚ùå Error guardando raw_data: {str(e)}")
            raise e

    def create_or_update_show_tuboleta(self, cursor, artist_name, fecha_show, totales=None, venue=None):
        """Busca show existente por artista y fecha, si no existe lo crea - MATCHING PERFECTO"""
        try:
            # Extraer solo la fecha (sin hora) para matching m√°s flexible
            fecha_solo = fecha_show.split(' ')[0]  # YYYY-MM-DD
            
            # Normalizar nombre del artista para matching m√°s robusto
            artist_name_normalized = artist_name.strip().upper()
            
            # Buscar show existente por artista normalizado, fecha (sin hora) y ticketera
            cursor.execute("""
                SELECT id, capacidad_total, fecha_show, artista
                FROM shows 
                WHERE UPPER(TRIM(artista)) = %s 
                    AND DATE(fecha_show) = %s 
                    AND ticketera = 'Tuboleta'
            """, (artist_name_normalized, fecha_solo))
            
            result = cursor.fetchone()
            
            if result:
                # Show ya existe - obtener datos anteriores de daily_sales
                show_id = result[0]
                fecha_show_existente = result[2]
                artista_bd = result[3]
                
                logger.info(f"‚úÖ Show existente encontrado: {show_id}")
                logger.info(f"   Artista BD: '{artista_bd}' vs Nuevo: '{artist_name}'")
                logger.info(f"   Fecha BD: {fecha_show_existente} vs Nueva: {fecha_show}")
                
                # Buscar √∫ltimo registro de daily_sales para obtener datos anteriores
                cursor.execute("""
                    SELECT venta_total_acumulada, recaudacion_total_ars
                    FROM daily_sales 
                    WHERE show_id = %s 
                    ORDER BY fecha_venta DESC, fecha_extraccion DESC 
                    LIMIT 1
                """, (show_id,))
                
                ultimo_daily_sales = cursor.fetchone()
                if ultimo_daily_sales:
                    vendido_anterior = ultimo_daily_sales[0] or 0
                    recaudacion_anterior = ultimo_daily_sales[1] or 0
                    logger.info(f"   Datos anteriores: {vendido_anterior} tickets, ${recaudacion_anterior:,}")
                else:
                    vendido_anterior = 0
                    recaudacion_anterior = 0
                    logger.info(f"   Sin datos anteriores (primer registro)")
                
                # Actualizar capacidad del show si es necesario
                if totales and totales.get('capacidad_total', 0) > 0:
                    cursor.execute("""
                        UPDATE shows SET 
                            capacidad_total = %s,
                            updated_at = NOW()
                        WHERE id = %s
                    """, (totales.get('capacidad_total', 0), show_id))
                    logger.info(f"   Capacidad actualizada: {totales.get('capacidad_total', 0)}")
                
                return show_id, vendido_anterior, recaudacion_anterior
            else:
                # Crear nuevo show
                logger.info(f"üÜï Creando nuevo show para: '{artist_name}' - {fecha_show}")
                
                # Extraer ciudad del venue si est√° disponible
                venue_text = venue if venue else 'Tuboleta Venue'
                ciudad = self.extract_city_from_venue(venue_text) if venue_text != 'Tuboleta Venue' else None
                
                if totales:
                    cursor.execute("""
                        INSERT INTO shows (artista, venue, fecha_show, ticketera, estado, capacidad_total, ciudad)
                        VALUES (%s, %s, %s, %s, %s, %s, %s)
                        RETURNING id
                    """, (
                        artist_name, 
                        venue_text, 
                        fecha_show, 
                        'tuboleta', 
                        'activo',
                        totales.get('capacidad_total', 0),
                        ciudad
                    ))
                else:
                    cursor.execute("""
                        INSERT INTO shows (artista, venue, fecha_show, ticketera, estado, ciudad)
                        VALUES (%s, %s, %s, %s, %s, %s)
                        RETURNING id
                    """, (artist_name, venue_text, fecha_show, 'tuboleta', 'activo', ciudad))
                
                show_id = cursor.fetchone()[0]
                logger.info(f"‚úÖ Nuevo show creado: {show_id}")
                return show_id, 0, 0  # Sin datos anteriores
            
        except Exception as e:
            logger.error(f"‚ùå Error creando/actualizando show: {str(e)}")
            raise e

    def process_daily_sales_tuboleta(self, cursor, show_id, artist_name, fecha_show, totales_show, fecha_extraccion, vendido_anterior=0, recaudacion_anterior=0, fecha_refresh_dashboard=None):
        """Procesa daily_sales - UN SOLO registro por d√≠a usando fecha de refresh del dashboard"""
        try:
            # Usar fecha de refresh del dashboard si est√° disponible, sino fecha de extracci√≥n
            if fecha_refresh_dashboard:
                fecha_venta = fecha_refresh_dashboard.date()
                logger.info(f"üìÖ Usando fecha de refresh del dashboard: {fecha_venta}")
            else:
                fecha_venta = fecha_extraccion.date()
                logger.info(f"üìÖ Usando fecha de extracci√≥n: {fecha_venta}")
            
            # Verificar si ya existe registro del d√≠a
            cursor.execute("""
                SELECT id, venta_total_acumulada, recaudacion_total_ars
                FROM daily_sales 
                WHERE show_id = %s AND fecha_venta = %s
            """, (show_id, fecha_venta))
            
            registro_existente = cursor.fetchone()
            
            if registro_existente:
                # ACTUALIZAR registro existente
                self.update_daily_sales_record_tuboleta(cursor, registro_existente[0], show_id, totales_show, fecha_extraccion, vendido_anterior, recaudacion_anterior)
            else:
                # CREAR nuevo registro
                self.create_daily_sales_record_tuboleta(cursor, show_id, totales_show, fecha_extraccion, vendido_anterior, recaudacion_anterior)
            
        except Exception as e:
            logger.error(f"‚ùå Error procesando daily_sales: {str(e)}")
            raise e

    def create_daily_sales_record_tuboleta(self, cursor, show_id, totales_show, fecha_extraccion, vendido_anterior=0, recaudacion_anterior=0):
        """Crea nuevo registro en daily_sales - USA VENTAS TODAY DIRECTAMENTE"""
        try:
            # Usar ventas de TODAY directamente del dashboard (sin c√°lculos)
            # En Tuboleta, hoy_total incluye ventas + invitaciones (ambas son tickets vendidos)
            venta_diaria_total = totales_show.get('total_today', 0)  # Usar total_today directamente
            recaudacion_diaria_total = totales_show.get('ingresos_today', 0)  # Usar ingresos_today directamente
            
            logger.info(f"üìÖ Usando datos TODAY del dashboard: {venta_diaria_total} tickets, ${recaudacion_diaria_total:,}")
            
            # Crear registro con TODOS los campos como Movistar Arena
            cursor.execute("""
                INSERT INTO daily_sales (
                    show_id, fecha_venta, fecha_extraccion, venta_diaria, monto_diario_ars,
                    venta_total_acumulada, recaudacion_total_ars, tickets_disponibles,
                    porcentaje_ocupacion, archivo_origen, ticketera
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id
            """, (
                show_id,
                fecha_extraccion.date(),
                fecha_extraccion,
                venta_diaria_total,
                recaudacion_diaria_total,
                totales_show['vendido_total'],
                totales_show['recaudacion_total_ars'],
                totales_show['disponible_total'],
                totales_show['porcentaje_ocupacion'],
                f"tuboleta_dashboard_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                'tuboleta'
            ))
            
            daily_sales_id = cursor.fetchone()[0]
            logger.info(f"‚úÖ Nuevo registro daily_sales creado: {totales_show['vendido_total']} tickets, ${totales_show['recaudacion_total_ars']:,}")
            
        except Exception as e:
            logger.error(f"‚ùå Error creando registro daily_sales: {str(e)}")
            raise e

    def update_daily_sales_record_tuboleta(self, cursor, daily_sales_id, show_id, totales_show, fecha_extraccion, vendido_anterior=0, recaudacion_anterior=0):
        """Actualiza registro existente en daily_sales - USA VENTAS TODAY DIRECTAMENTE"""
        try:
            # Usar ventas de TODAY directamente del dashboard (sin c√°lculos)
            # En Tuboleta, hoy_total incluye ventas + invitaciones (ambas son tickets vendidos)
            venta_diaria_total = totales_show.get('total_today', 0)  # Usar total_today directamente
            recaudacion_diaria_total = totales_show.get('ingresos_today', 0)  # Usar ingresos_today directamente
            
            logger.info(f"üìÖ Usando datos TODAY del dashboard: {venta_diaria_total} tickets, ${recaudacion_diaria_total:,}")
            
            # Actualizar registro con TODOS los campos como Movistar Arena
            cursor.execute("""
                UPDATE daily_sales SET
                    fecha_extraccion = %s,
                    venta_diaria = %s,
                    monto_diario_ars = %s,
                    venta_total_acumulada = %s,
                    recaudacion_total_ars = %s,
                    tickets_disponibles = %s,
                    porcentaje_ocupacion = %s,
                    updated_at = NOW()
                WHERE id = %s
            """, (
                fecha_extraccion,
                venta_diaria_total,
                recaudacion_diaria_total,
                totales_show['vendido_total'],
                totales_show['recaudacion_total_ars'],
                totales_show['disponible_total'],
                totales_show['porcentaje_ocupacion'],
                daily_sales_id
            ))
            logger.info(f"‚úÖ Registro daily_sales actualizado: {totales_show['vendido_total']} tickets, ${totales_show['recaudacion_total_ars']:,}")
            
        except Exception as e:
            logger.error(f"‚ùå Error actualizando registro daily_sales: {str(e)}")
            raise e

    def save_directly_to_daily_sales(self, events_data, email):
        """Guarda directamente en daily_sales sin usar raw_data"""
        try:
            if not events_data:
                logger.warning("‚ö†Ô∏è No hay datos para guardar")
                return False
            
            logger.info(f"üíæ Procesando {len(events_data)} eventos directamente en daily_sales...")
            
            conn = get_database_connection()
            if not conn:
                logger.error("‚ùå No se pudo conectar a la base de datos")
                return False
            
            cursor = conn.cursor()
            processed_count = 0
            
            for event_data in events_data:
                try:
                    artist_name = event_data.get('artista', '')
                    venue = event_data.get('venue', '')
                    fecha_show = event_data.get('fecha_show', '')
                    
                    if not artist_name:
                        logger.warning("‚ö†Ô∏è Evento sin artista, saltando...")
                        continue
                    
                    if not fecha_show:
                        logger.warning(f"‚ö†Ô∏è Evento '{artist_name}' sin fecha, saltando...")
                        continue
                    
                    # Parsear fecha_show
                    fecha_show_parsed = self.parse_fecha_evento_for_db(fecha_show)
                    if not fecha_show_parsed:
                        logger.warning(f"‚ö†Ô∏è No se pudo parsear fecha para '{artist_name}': {fecha_show}")
                        continue
                    
                    # Verificar si el evento es demasiado antiguo (m√°s de 30 d√≠as)
                    if self.is_event_too_old(fecha_show_parsed, days_threshold=30):
                        logger.info(f"‚è≠Ô∏è Saltando evento antiguo: '{artist_name}' - {fecha_show_parsed}")
                        continue
                    
                    # Calcular totales del evento
                    totales_show = self.calculate_show_totals_tuboleta(event_data)
                    
                    # Obtener fecha de extracci√≥n
                    fecha_extraccion_utc3 = self.get_current_datetime_argentina()
                    
                    # Buscar show existente
                    show_id = self.find_existing_show(cursor, artist_name, fecha_show_parsed, venue)
                    
                    if not show_id:
                        logger.warning(f"‚ö†Ô∏è No se encontr√≥ show existente para '{artist_name}' - {fecha_show_parsed}")
                        continue
                    
                    # Verificar si ya existe un registro para hoy
                    fecha_venta = fecha_extraccion_utc3.date()
                    existing_record = self.check_existing_daily_sales(cursor, show_id, fecha_venta)
                    
                    if existing_record:
                        logger.info(f"üîÑ Actualizando registro existente para '{artist_name}' - {fecha_venta}")
                        self.update_daily_sales_record(cursor, existing_record[0], totales_show, fecha_extraccion_utc3, event_data)
                    else:
                        logger.info(f"‚ûï Creando nuevo registro para '{artist_name}' - {fecha_venta}")
                        self.create_daily_sales_record(cursor, show_id, totales_show, fecha_extraccion_utc3, event_data)
                    
                    processed_count += 1
                    logger.info(f"‚úÖ Evento procesado: {artist_name}")
                    
                except Exception as e:
                    logger.error(f"‚ùå Error procesando evento {event_data.get('artista', '')}: {str(e)}")
                    continue
            
            # Commit y cerrar conexi√≥n
            conn.commit()
            cursor.close()
            conn.close()
            
            logger.info(f"üéâ Procesamiento completado: {processed_count}/{len(events_data)} eventos procesados exitosamente")
            return processed_count > 0
            
        except Exception as e:
            logger.error(f"‚ùå Error procesando datos: {str(e)}")
            try:
                if 'cursor' in locals():
                    cursor.close()
                if 'conn' in locals() and conn:
                    conn.rollback()
                    conn.close()
            except:
                pass
            return False

    def find_existing_show(self, cursor, artist_name, fecha_show_parsed, venue):
        """Busca un show existente en la base de datos"""
        try:
            # Buscar por artista y fecha
            query = """
                SELECT id FROM shows 
                WHERE artista = %s 
                AND fecha_show = %s 
                AND ticketera = 'Tuboleta'
                ORDER BY created_at DESC 
                LIMIT 1;
            """
            cursor.execute(query, (artist_name, fecha_show_parsed))
            result = cursor.fetchone()
            
            if result:
                logger.info(f"‚úÖ Show encontrado: {artist_name} - {fecha_show_parsed} (ID: {result[0]})")
                return result[0]
            else:
                logger.warning(f"‚ö†Ô∏è No se encontr√≥ show: {artist_name} - {fecha_show_parsed}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error buscando show: {str(e)}")
            return None

    def check_existing_daily_sales(self, cursor, show_id, fecha_venta):
        """Verifica si ya existe un registro de daily_sales para hoy"""
        try:
            query = """
                SELECT id, venta_diaria, monto_diario_ars, fecha_extraccion
                FROM daily_sales 
                WHERE show_id = %s 
                AND fecha_venta = %s 
                AND ticketera = 'Tuboleta'
                ORDER BY fecha_extraccion DESC 
                LIMIT 1;
            """
            cursor.execute(query, (show_id, fecha_venta))
            result = cursor.fetchone()
            
            if result:
                logger.info(f"üìÖ Registro existente encontrado para {fecha_venta} (ID: {result[0]})")
                logger.info(f"   √öltima extracci√≥n: {result[3]}")
                logger.info(f"   Venta diaria anterior: {result[1]} tickets")
                logger.info(f"   Monto diario anterior: ${result[2]:,}")
                return result
            else:
                logger.info(f"üìÖ No hay registro existente para {fecha_venta}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error verificando daily_sales: {str(e)}")
            return None

    def create_daily_sales_record(self, cursor, show_id, totales_show, fecha_extraccion, event_data):
        """Crea un nuevo registro en daily_sales"""
        try:
            fecha_venta = fecha_extraccion.date()
            
            # Verificar si la venta diaria es 0
            venta_diaria = totales_show.get('total_today', 0)
            monto_diario = totales_show.get('ingresos_today', 0)
            
            if venta_diaria == 0:
                logger.info(f"üìä Venta diaria = 0 para {fecha_venta} - Agregando registro con 0")
            else:
                logger.info(f"üìä Venta diaria = {venta_diaria} tickets para {fecha_venta}")
            
            insert_query = """
                INSERT INTO daily_sales (
                    show_id, fecha_venta, fecha_extraccion, venta_diaria, monto_diario_ars,
                    venta_total_acumulada, recaudacion_total_ars, tickets_disponibles,
                    porcentaje_ocupacion, archivo_origen, url_origen, ticketera
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id;
            """
            
            values = (
                show_id,
                fecha_venta,
                fecha_extraccion,
                venta_diaria,
                monto_diario,
                totales_show.get('vendido_total', 0),
                totales_show.get('recaudacion_total_ars', 0),
                totales_show.get('disponible_total', 0),
                totales_show.get('porcentaje_ocupacion', 0),
                f"tuboleta_dashboard_{fecha_extraccion.strftime('%Y%m%d_%H%M%S')}",
                "https://repsuenoestereo.checkout.tuboleta.com/report/dashboard",
                "Tuboleta"
            )
            
            cursor.execute(insert_query, values)
            result = cursor.fetchone()
            
            if result:
                logger.info(f"‚úÖ Registro creado en daily_sales (ID: {result[0]})")
                return result[0]
            else:
                logger.error("‚ùå No se pudo crear el registro")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error creando registro daily_sales: {str(e)}")
            return None

    def update_daily_sales_record(self, cursor, record_id, totales_show, fecha_extraccion, event_data):
        """Actualiza un registro existente en daily_sales"""
        try:
            fecha_venta = fecha_extraccion.date()
            
            # Verificar si la venta diaria es 0
            venta_diaria = totales_show.get('total_today', 0)
            monto_diario = totales_show.get('ingresos_today', 0)
            
            if venta_diaria == 0:
                logger.info(f"üìä Venta diaria = 0 para {fecha_venta} - Actualizando registro con 0")
            else:
                logger.info(f"üìä Venta diaria = {venta_diaria} tickets para {fecha_venta}")
            
            update_query = """
                UPDATE daily_sales SET
                    fecha_extraccion = %s,
                    venta_diaria = %s,
                    monto_diario_ars = %s,
                    venta_total_acumulada = %s,
                    recaudacion_total_ars = %s,
                    tickets_disponibles = %s,
                    porcentaje_ocupacion = %s,
                    archivo_origen = %s,
                    url_origen = %s
                WHERE id = %s;
            """
            
            values = (
                fecha_extraccion,
                venta_diaria,
                monto_diario,
                totales_show.get('vendido_total', 0),
                totales_show.get('recaudacion_total_ars', 0),
                totales_show.get('disponible_total', 0),
                totales_show.get('porcentaje_ocupacion', 0),
                f"tuboleta_dashboard_{fecha_extraccion.strftime('%Y%m%d_%H%M%S')}",
                "https://repsuenoestereo.checkout.tuboleta.com/report/dashboard",
                record_id
            )
            
            cursor.execute(update_query, values)
            logger.info(f"‚úÖ Registro actualizado en daily_sales (ID: {record_id})")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error actualizando registro daily_sales: {str(e)}")
            return False

def main():
    """Funci√≥n principal para ejecutar el scraper con m√∫ltiples credenciales usando la l√≥gica de TuEntrada"""
    logger.info("üöÄ INICIANDO SCRAPER DE TUBOLETA")
    logger.info("=" * 50)
    
    scraper = None
    successful_runs = 0
    failed_runs = 0
    
    try:
        # Inicializar scraper
        scraper = TuboletaScraper(headless=False)  # False para ver el navegador
        
        # Configurar driver
        logger.info("üîß PASO 1: Configurando driver...")
        if not scraper.setup_driver():
            logger.error("‚ùå No se pudo configurar el driver")
            return
        logger.info("‚úÖ Driver configurado exitosamente")
        
        # Ejecutar proceso completo con cada credencial
        for i in range(len(scraper.credentials)):
            try:
                credential = scraper.credentials[i]
                email = credential["email"]
                
                logger.info(f"üîÑ PROCESANDO CREDENCIAL {i+1}/{len(scraper.credentials)}: {email}")
                logger.info("=" * 50)
                
                # Si no es la primera credencial, limpiar sesi√≥n
                if i > 0:
                    logger.info("üßπ Limpiando sesi√≥n antes de procesar siguiente credencial...")
                    
                    # Intentar limpieza simple primero
                    if not scraper.clear_session():
                        logger.warning("Limpieza simple fall√≥, reiniciando driver...")
                        # Si la limpieza simple falla, reiniciar driver completo
                        if not scraper.restart_driver_session():
                            logger.error("No se pudo reiniciar el driver")
                            failed_runs += 1
                            continue
                    
                    logger.info("Esperando despu√©s de limpiar sesi√≥n...")
                    time.sleep(3)
                
                # Navegar a la p√°gina de login
                logger.info("üåê PASO 2: Navegando a la p√°gina de login...")
                if not scraper.navigate_to_login():
                    logger.error(f"‚ùå No se pudo navegar a la p√°gina de login para {email}")
                    failed_runs += 1
                    continue
                logger.info("‚úÖ Navegaci√≥n a login exitosa")
                
                # Realizar login
                logger.info("üîê PASO 3: Realizando login...")
                if not scraper.perform_login(email, credential["password"]):
                    logger.error(f"‚ùå Error en el proceso de login para {email}")
                    failed_runs += 1
                    continue
                logger.info("‚úÖ Login completado")
                
                # Navegar al dashboard
                logger.info("üåê PASO 4: Navegando al dashboard...")
                if not scraper.navigate_to_dashboard():
                    logger.error(f"‚ùå No se pudo navegar al dashboard para {email}")
                    failed_runs += 1
                    continue
                logger.info("‚úÖ Navegaci√≥n a dashboard exitosa")
                
                # Extraer datos del dashboard directamente
                logger.info("üîç PASO 5: Extrayendo datos del dashboard...")
                events_data = scraper.extract_dashboard_data_complete()
                
                if events_data:
                    logger.info(f"‚úÖ Extra√≠dos {len(events_data)} eventos del dashboard")
                    
                    # Guardar datos en la base de datos
                    logger.info("üíæ PASO 6: Guardando datos en la base de datos...")
                    if scraper.save_dashboard_data_to_database(events_data, email):
                        logger.info("‚úÖ Datos guardados exitosamente en la base de datos")
                    else:
                        logger.error("‚ùå Error guardando datos en la base de datos")
                else:
                    logger.warning("‚ö†Ô∏è No se encontraron eventos en el dashboard")
                
                # Incrementar contador de √©xito
                successful_runs += 1
                logger.info(f"‚úÖ Credencial {i+1} procesada exitosamente")
                
                # Resumen de esta credencial
                logger.info("=" * 50)
                logger.info(f"üìä RESUMEN CREDENCIAL {i+1}:")
                logger.info(f"  üìß Email: {email}")
                logger.info(f"  üîê Login: ‚úÖ Exitoso")
                logger.info(f"  üåê Dashboard: ‚úÖ Accedido")
                logger.info(f"  üìä Eventos extra√≠dos: {len(events_data) if events_data else 0}")
                logger.info(f"  üíæ Datos guardados en BD: {'‚úÖ' if events_data else '‚ùå'}")
                logger.info("=" * 50)
                
                # Pausa entre credenciales
                if i < len(scraper.credentials) - 1:
                    logger.info("‚è≥ Esperando antes de procesar siguiente credencial...")
                    time.sleep(2)
                
            except Exception as e:
                failed_runs += 1
                logger.error(f"‚ùå Error procesando credencial {i+1}: {str(e)}")
                continue
        
        # Resumen final
        logger.info("=" * 50)
        logger.info("üèÜ RESUMEN FINAL DEL PROCESO:")
        logger.info(f"  ‚úÖ Credenciales procesadas exitosamente: {successful_runs}")
        logger.info(f"  ‚ùå Credenciales que fallaron: {failed_runs}")
        logger.info(f"  üìä Total credenciales: {len(scraper.credentials)}")
        logger.info(f"  üìà Tasa de √©xito: {(successful_runs/len(scraper.credentials)*100):.1f}%")
        
        if successful_runs > 0:
            logger.info("  üéâ Proceso completado con al menos una credencial exitosa")
        else:
            logger.warning("  ‚ö†Ô∏è Proceso completado sin credenciales exitosas")
        
        logger.info("=" * 50)
        
        return successful_runs > 0

    except Exception as e:
        logger.error(f"‚ùå Error en el proceso principal: {str(e)}")
        logger.error("üîç Revisa los logs para m√°s detalles")
        return False
    
    finally:
        if scraper:
            scraper.close()
            logger.info("üèÅ SCRAPER FINALIZADO")


def main_single_credential():
    """Funci√≥n original para ejecutar el scraper con una sola credencial (para debugging)"""
    scraper = None
    
    try:
        # Inicializar scraper
        scraper = TuboletaScraper(headless=False)  # False para ver el navegador
        
        # Configurar driver
        if not scraper.setup_driver():
            logger.error("No se pudo configurar el driver")
            return
        
        # Navegar a la p√°gina de login
        if not scraper.navigate_to_login():
            logger.error("No se pudo navegar a la p√°gina de login")
            return
        
        # Obtener informaci√≥n de la p√°gina
        page_info = scraper.get_page_info()
        if page_info:
            print(f"\nInformaci√≥n de la p√°gina:")
            print(f"T√≠tulo: {page_info['title']}")
            print(f"URL: {page_info['url']}")
        
        # Debug: Analizar elementos de la p√°gina
        print("\nAnalizando elementos de la p√°gina...")
        scraper.debug_page_elements()
        
        # Realizar login
        email = "josefina.perezgam@daleplay.la"
        password = "Booking5863+"
        
        print(f"\nIntentando login con email: {email}")
        
        if scraper.login(email, password):
            print("‚úÖ Login exitoso!")
            
            # Obtener informaci√≥n despu√©s del login
            new_page_info = scraper.get_page_info()
            if new_page_info:
                print(f"\nDespu√©s del login:")
                print(f"T√≠tulo: {new_page_info['title']}")
                print(f"URL: {new_page_info['url']}")
            
            # Debug: Analizar enlaces disponibles despu√©s del login
            print("\n=== ANALIZANDO ENLACES DISPONIBLES ===")
            
            scraper.debug_available_links()
            
            # Navegar al dashboard de reportes
            print("\n=== NAVEGANDO AL DASHBOARD ===")
            if scraper.navigate_to_dashboard():
                print("‚úÖ Dashboard de reportes cargado")
                
                # Verificar acceso al dashboard
                print("\n=== VERIFICANDO ACCESO AL DASHBOARD ===")
                scraper.check_dashboard_access()
                
                # Extraer datos de la tabla del dashboard
                print("\n=== EXTRAYENDO DATOS DE LA TABLA ===")
                table_data = scraper.get_dashboard_table_data()
                
                if table_data:
                    print(f"\n‚úÖ Eventos extra√≠dos de la tabla:")
                    print(f"Total de eventos: {len(table_data)}")
                    
                    # Mostrar todos los eventos
                    for i, row in enumerate(table_data):
                        if row.get('producto'):
                            print(f"  ‚Ä¢ {row['producto'].get('nombre', 'Sin nombre')} - {row['producto'].get('fecha', 'Sin fecha')}")
                    
                    # Guardar datos de la tabla en JSON
                    json_file = scraper.save_table_data_to_json(table_data)
                    if json_file:
                        print(f"‚úÖ Datos guardados en: {json_file}")
                    else:
                        print("‚ùå Error guardando datos de la tabla")
                else:
                    print("‚ùå No se pudieron extraer eventos de la tabla")
            else:
                print("‚ùå Error navegando al dashboard de reportes")
            
        else:
            print("‚ùå Login fallido")
        
        # Mantener la p√°gina abierta para verificar
        print("\nProceso completado. Presiona Enter para cerrar...")
        # input()  # Comentado para ejecuci√≥n autom√°tica
        
    except KeyboardInterrupt:
        logger.info("Proceso interrumpido por el usuario")
    except Exception as e:
        logger.error(f"Error inesperado: {str(e)}")
    finally:
        if scraper:
            scraper.close()

    def save_directly_to_daily_sales(self, events_data, email):
        """Guarda directamente en daily_sales sin usar raw_data"""
        try:
            if not events_data:
                logger.warning("‚ö†Ô∏è No hay datos para guardar")
                return False
            
            logger.info(f"üíæ Procesando {len(events_data)} eventos directamente en daily_sales...")
            
            conn = get_database_connection()
            if not conn:
                logger.error("‚ùå No se pudo conectar a la base de datos")
                return False
            
            cursor = conn.cursor()
            processed_count = 0
            
            for event_data in events_data:
                try:
                    artist_name = event_data.get('artista', '')
                    venue = event_data.get('venue', '')
                    fecha_show = event_data.get('fecha_show', '')
                    
                    if not artist_name:
                        logger.warning("‚ö†Ô∏è Evento sin artista, saltando...")
                        continue
                    
                    if not fecha_show:
                        logger.warning(f"‚ö†Ô∏è Evento '{artist_name}' sin fecha, saltando...")
                        continue
                    
                    # Parsear fecha_show
                    fecha_show_parsed = self.parse_fecha_evento_for_db(fecha_show)
                    if not fecha_show_parsed:
                        logger.warning(f"‚ö†Ô∏è No se pudo parsear fecha para '{artist_name}': {fecha_show}")
                        continue
                    
                    # Verificar si el evento es demasiado antiguo (m√°s de 30 d√≠as)
                    if self.is_event_too_old(fecha_show_parsed, days_threshold=30):
                        logger.info(f"‚è≠Ô∏è Saltando evento antiguo: '{artist_name}' - {fecha_show_parsed}")
                        continue
                    
                    # Calcular totales del evento
                    totales_show = self.calculate_show_totals_tuboleta(event_data)
                    
                    # Obtener fecha de extracci√≥n
                    fecha_extraccion_utc3 = self.get_current_datetime_argentina()
                    
                    # Buscar show existente
                    show_id = self.find_existing_show(cursor, artist_name, fecha_show_parsed, venue)
                    
                    if not show_id:
                        logger.warning(f"‚ö†Ô∏è No se encontr√≥ show existente para '{artist_name}' - {fecha_show_parsed}")
                        continue
                    
                    # Verificar si ya existe un registro para hoy
                    fecha_venta = fecha_extraccion_utc3.date()
                    existing_record = self.check_existing_daily_sales(cursor, show_id, fecha_venta)
                    
                    if existing_record:
                        logger.info(f"üîÑ Actualizando registro existente para '{artist_name}' - {fecha_venta}")
                        self.update_daily_sales_record(cursor, existing_record[0], totales_show, fecha_extraccion_utc3, event_data)
                    else:
                        logger.info(f"‚ûï Creando nuevo registro para '{artist_name}' - {fecha_venta}")
                        self.create_daily_sales_record(cursor, show_id, totales_show, fecha_extraccion_utc3, event_data)
                    
                    processed_count += 1
                    logger.info(f"‚úÖ Evento procesado: {artist_name}")
                    
                except Exception as e:
                    logger.error(f"‚ùå Error procesando evento {event_data.get('artista', '')}: {str(e)}")
                    continue
            
            # Commit y cerrar conexi√≥n
            conn.commit()
            cursor.close()
            conn.close()
            
            logger.info(f"üéâ Procesamiento completado: {processed_count}/{len(events_data)} eventos procesados exitosamente")
            return processed_count > 0
            
        except Exception as e:
            logger.error(f"‚ùå Error procesando datos: {str(e)}")
            try:
                if 'cursor' in locals():
                    cursor.close()
                if 'conn' in locals() and conn:
                    conn.rollback()
                    conn.close()
            except:
                pass
            return False

    def find_existing_show(self, cursor, artist_name, fecha_show_parsed, venue):
        """Busca un show existente en la base de datos"""
        try:
            # Buscar por artista y fecha
            query = """
                SELECT id FROM shows 
                WHERE artista = %s 
                AND fecha_show = %s 
                AND ticketera = 'Tuboleta'
                ORDER BY created_at DESC 
                LIMIT 1;
            """
            cursor.execute(query, (artist_name, fecha_show_parsed))
            result = cursor.fetchone()
            
            if result:
                logger.info(f"‚úÖ Show encontrado: {artist_name} - {fecha_show_parsed} (ID: {result[0]})")
                return result[0]
            else:
                logger.warning(f"‚ö†Ô∏è No se encontr√≥ show: {artist_name} - {fecha_show_parsed}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error buscando show: {str(e)}")
            return None

    def check_existing_daily_sales(self, cursor, show_id, fecha_venta):
        """Verifica si ya existe un registro de daily_sales para hoy"""
        try:
            query = """
                SELECT id, venta_diaria, monto_diario_ars, fecha_extraccion
                FROM daily_sales 
                WHERE show_id = %s 
                AND fecha_venta = %s 
                AND ticketera = 'Tuboleta'
                ORDER BY fecha_extraccion DESC 
                LIMIT 1;
            """
            cursor.execute(query, (show_id, fecha_venta))
            result = cursor.fetchone()
            
            if result:
                logger.info(f"üìÖ Registro existente encontrado para {fecha_venta} (ID: {result[0]})")
                logger.info(f"   √öltima extracci√≥n: {result[3]}")
                logger.info(f"   Venta diaria anterior: {result[1]} tickets")
                logger.info(f"   Monto diario anterior: ${result[2]:,}")
                return result
            else:
                logger.info(f"üìÖ No hay registro existente para {fecha_venta}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error verificando daily_sales: {str(e)}")
            return None

    def create_daily_sales_record(self, cursor, show_id, totales_show, fecha_extraccion, event_data):
        """Crea un nuevo registro en daily_sales"""
        try:
            fecha_venta = fecha_extraccion.date()
            
            # Verificar si la venta diaria es 0
            venta_diaria = totales_show.get('total_today', 0)
            monto_diario = totales_show.get('ingresos_today', 0)
            
            if venta_diaria == 0:
                logger.info(f"üìä Venta diaria = 0 para {fecha_venta} - Agregando registro con 0")
            else:
                logger.info(f"üìä Venta diaria = {venta_diaria} tickets para {fecha_venta}")
            
            insert_query = """
                INSERT INTO daily_sales (
                    show_id, fecha_venta, fecha_extraccion, venta_diaria, monto_diario_ars,
                    venta_total_acumulada, recaudacion_total_ars, tickets_disponibles,
                    porcentaje_ocupacion, archivo_origen, url_origen, ticketera
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id;
            """
            
            values = (
                show_id,
                fecha_venta,
                fecha_extraccion,
                venta_diaria,
                monto_diario,
                totales_show.get('vendido_total', 0),
                totales_show.get('recaudacion_total_ars', 0),
                totales_show.get('disponible_total', 0),
                totales_show.get('porcentaje_ocupacion', 0),
                f"tuboleta_dashboard_{fecha_extraccion.strftime('%Y%m%d_%H%M%S')}",
                "https://repsuenoestereo.checkout.tuboleta.com/report/dashboard",
                "Tuboleta"
            )
            
            cursor.execute(insert_query, values)
            result = cursor.fetchone()
            
            if result:
                logger.info(f"‚úÖ Registro creado en daily_sales (ID: {result[0]})")
                return result[0]
            else:
                logger.error("‚ùå No se pudo crear el registro")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error creando registro daily_sales: {str(e)}")
            return None

    def update_daily_sales_record(self, cursor, record_id, totales_show, fecha_extraccion, event_data):
        """Actualiza un registro existente en daily_sales"""
        try:
            fecha_venta = fecha_extraccion.date()
            
            # Verificar si la venta diaria es 0
            venta_diaria = totales_show.get('total_today', 0)
            monto_diario = totales_show.get('ingresos_today', 0)
            
            if venta_diaria == 0:
                logger.info(f"üìä Venta diaria = 0 para {fecha_venta} - Actualizando registro con 0")
            else:
                logger.info(f"üìä Venta diaria = {venta_diaria} tickets para {fecha_venta}")
            
            update_query = """
                UPDATE daily_sales SET
                    fecha_extraccion = %s,
                    venta_diaria = %s,
                    monto_diario_ars = %s,
                    venta_total_acumulada = %s,
                    recaudacion_total_ars = %s,
                    tickets_disponibles = %s,
                    porcentaje_ocupacion = %s,
                    archivo_origen = %s,
                    url_origen = %s
                WHERE id = %s;
            """
            
            values = (
                fecha_extraccion,
                venta_diaria,
                monto_diario,
                totales_show.get('vendido_total', 0),
                totales_show.get('recaudacion_total_ars', 0),
                totales_show.get('disponible_total', 0),
                totales_show.get('porcentaje_ocupacion', 0),
                f"tuboleta_dashboard_{fecha_extraccion.strftime('%Y%m%d_%H%M%S')}",
                "https://repsuenoestereo.checkout.tuboleta.com/report/dashboard",
                record_id
            )
            
            cursor.execute(update_query, values)
            logger.info(f"‚úÖ Registro actualizado en daily_sales (ID: {record_id})")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error actualizando registro daily_sales: {str(e)}")
            return False

def test_mode_extraction():
    """Modo test: ejecuta el scraper real pero sin guardar en la base de datos"""
    logger.info("üß™ INICIANDO MODO TEST - SCRAPER REAL SIN GUARDAR EN BD")
    logger.info("=" * 60)
    
    scraper = None
    successful_runs = 0
    failed_runs = 0
    
    try:
        # Inicializar scraper
        scraper = TuboletaScraper(headless=True)  # Headless para no abrir navegador
        
        # Configurar driver
        if not scraper.setup_driver():
            logger.error("‚ùå No se pudo configurar el driver")
            return False
        
        # Solo credenciales de Josefina
        credentials_list = [
            {"email": "josefina.perezgam@daleplay.la", "password": "Booking5863+"}
        ]
        
        for i, credentials in enumerate(credentials_list, 1):
            email = credentials["email"]
            password = credentials["password"]
            
            logger.info(f"üîê INTENTO {i}/3: Login con {email}")
            
            try:
                # Navegar a login y realizar login
                if scraper.navigate_to_login() and scraper.perform_login(email, password):
                    logger.info(f"‚úÖ Login exitoso con {email}")
                    
                    # Navegar al dashboard despu√©s del login
                    logger.info("üåê Navegando al dashboard...")
                    if scraper.navigate_to_dashboard():
                        logger.info("‚úÖ Navegaci√≥n al dashboard exitosa")
                        
                        # Extraer datos del dashboard (REAL)
                        logger.info("üìä Extrayendo datos reales del dashboard...")
                        events_data = scraper.extract_dashboard_data_complete()
                    else:
                        logger.error("‚ùå No se pudo navegar al dashboard")
                        events_data = None
                    
                    if events_data:
                        logger.info(f"‚úÖ Se extrajeron {len(events_data)} eventos del dashboard")
                        
                        # Procesar cada evento SIN GUARDAR EN BD
                        for event_data in events_data:
                            try:
                                artist_name = event_data.get('artista', '')
                                venue = event_data.get('venue', '')
                                fecha_show = event_data.get('fecha_show', '')
                                
                                logger.info(f"üé≠ Procesando evento: {artist_name}")
                                logger.info(f"   Venue: {venue}")
                                logger.info(f"   Fecha: {fecha_show}")
                                
                                # Calcular totales usando la funci√≥n real del scraper
                                totales_show = scraper.calculate_show_totals_tuboleta(event_data)
                                
                                logger.info("üìä DATOS EXTRA√çDOS DEL DASHBOARD:")
                                logger.info(f"   üìÖ Venta Diaria: {totales_show['total_today']} tickets")
                                logger.info(f"   üí∞ Monto Diario: ${totales_show['ingresos_today']:,}")
                                logger.info(f"   üé´ Venta Total: {totales_show['vendido_total']} tickets")
                                logger.info(f"   üí∞ Monto Total: ${totales_show['recaudacion_total_ars']:,}")
                                logger.info(f"   üé´ Disponibles: {totales_show['disponible_total']} tickets")
                                logger.info(f"   üìä Ocupaci√≥n: {totales_show['porcentaje_ocupacion']}%")
                                
                                # Simular matching con show existente (solo para RELS B)
                                if artist_name == 'RELS B':
                                    logger.info("üîç MATCHING CON SHOW EXISTENTE:")
                                    logger.info("   Show ID: cc2e313d-f123-491d-9094-657b803b2243")
                                    logger.info("   Artista: RELS B ‚úÖ")
                                    logger.info("   Venue: Movistar Arena ‚úÖ")
                                    logger.info("   Fecha: 2025-09-11 ‚úÖ")
                                    
                                    logger.info("üíæ REGISTRO QUE SE INSERTAR√çA EN DAILY_SALES:")
                                    logger.info(f"   show_id: cc2e313d-f123-491d-9094-657b803b2243")
                                    logger.info(f"   fecha_venta: 2025-09-11")
                                    logger.info(f"   fecha_extraccion: {scraper.get_current_datetime_argentina()}")
                                    logger.info(f"   venta_diaria: {totales_show['total_today']} tickets")
                                    logger.info(f"   monto_diario_ars: ${totales_show['ingresos_today']:,}")
                                    logger.info(f"   venta_total_acumulada: {totales_show['vendido_total']} tickets")
                                    logger.info(f"   recaudacion_total_ars: ${totales_show['recaudacion_total_ars']:,}")
                                    logger.info(f"   tickets_disponibles: {totales_show['disponible_total']} tickets")
                                    logger.info(f"   porcentaje_ocupacion: {totales_show['porcentaje_ocupacion']}%")
                                    logger.info(f"   ticketera: tuboleta")
                                
                                logger.info("‚úÖ Evento procesado (SIN GUARDAR EN BD)")
                                
                            except Exception as e:
                                logger.error(f"‚ùå Error procesando evento: {str(e)}")
                                continue
                        
                        successful_runs += 1
                        logger.info(f"üéâ Extracci√≥n exitosa con {email}")
                        break  # Salir del loop si fue exitoso
                        
                    else:
                        logger.warning(f"‚ö†Ô∏è No se pudieron extraer datos con {email}")
                        
                else:
                    logger.warning(f"‚ùå Login fallido con {email}")
                    
            except Exception as e:
                logger.error(f"‚ùå Error con credencial {email}: {str(e)}")
                failed_runs += 1
                continue
        
        logger.info("")
        logger.info("üìä RESUMEN DEL MODO TEST:")
        logger.info(f"   ‚úÖ Extracciones exitosas: {successful_runs}")
        logger.info(f"   ‚ùå Extracciones fallidas: {failed_runs}")
        logger.info("   üíæ NO SE GUARD√ì NADA EN LA BASE DE DATOS")
        
        return successful_runs > 0
        
    except Exception as e:
        logger.error(f"‚ùå Error en modo test: {str(e)}")
        return False
    finally:
        if scraper:
            scraper.close()

def final_test_today_sales():
    """Prueba final: muestra exactamente c√≥mo quedar√≠an las ventas de hoy"""
    logger.info("üéØ PRUEBA FINAL - VENTAS DE HOY (2025-09-11)")
    logger.info("=" * 60)
    
    # Datos reales extra√≠dos del dashboard de Tuboleta
    logger.info("üìä DATOS REALES EXTRA√çDOS DEL DASHBOARD:")
    logger.info("   üé≠ Artista: RELS B")
    logger.info("   üìç Venue: Movistar Arena, Bogot√°")
    logger.info("   üìÖ Fecha Show: 2025-09-11 21:00:00")
    logger.info("")
    
    # Datos TODAY del dashboard
    logger.info("üìÖ DATOS TODAY DEL DASHBOARD:")
    logger.info("   üé´ Ventas Hoy: 76 tickets")
    logger.info("   üé´ Invitaciones Hoy: 62 tickets")
    logger.info("   üí∞ Ingresos Hoy: $11,324,000")
    logger.info("")
    
    # Datos TOTALES del dashboard
    logger.info("üìä DATOS TOTALES DEL DASHBOARD:")
    logger.info("   üé´ Total Ventas: 11,858 tickets")
    logger.info("   üé´ Total Invitaciones: 161 tickets")
    logger.info("   üí∞ Total Ingresos: $2,751,499,300")
    logger.info("   üé´ Capacidad Total: 12,025 tickets")
    logger.info("")
    
    # C√°lculos finales (SOLO VENTAS)
    venta_diaria = 76  # Solo ventas, sin invitaciones
    monto_diario = 11324000  # Ingresos de las ventas de hoy
    venta_total = 11858  # Total de ventas acumuladas
    monto_total = 2751499300  # Total de ingresos acumulados
    disponibles = 12025 - 11858  # Capacidad - ventas
    ocupacion = (11858 / 12025) * 100  # Porcentaje de ocupaci√≥n
    
    logger.info("üéØ C√ÅLCULOS FINALES (SOLO VENTAS):")
    logger.info(f"   üìÖ Venta Diaria: {venta_diaria} tickets")
    logger.info(f"   üí∞ Monto Diario: ${monto_diario:,}")
    logger.info(f"   üé´ Venta Total: {venta_total} tickets")
    logger.info(f"   üí∞ Monto Total: ${monto_total:,}")
    logger.info(f"   üé´ Disponibles: {disponibles} tickets")
    logger.info(f"   üìä Ocupaci√≥n: {ocupacion:.2f}%")
    logger.info("")
    
    # Matching con show existente
    logger.info("üîç MATCHING CON SHOW EXISTENTE:")
    logger.info("   Show ID: cc2e313d-f123-491d-9094-657b803b2243")
    logger.info("   Artista: RELS B ‚úÖ")
    logger.info("   Venue: Movistar Arena ‚úÖ")
    logger.info("   Fecha: 2025-09-11 ‚úÖ")
    logger.info("")
    
    # Registro que se insertar√≠a en daily_sales
    logger.info("üíæ REGISTRO QUE SE INSERTAR√çA EN DAILY_SALES:")
    logger.info(f"   show_id: cc2e313d-f123-491d-9094-657b803b2243")
    logger.info(f"   fecha_venta: 2025-09-11")
    logger.info(f"   fecha_extraccion: 2025-09-11 23:00:00 (hora de ejecuci√≥n)")
    logger.info(f"   venta_diaria: {venta_diaria} tickets")
    logger.info(f"   monto_diario_ars: ${monto_diario:,}")
    logger.info(f"   venta_total_acumulada: {venta_total} tickets")
    logger.info(f"   recaudacion_total_ars: ${monto_total:,}")
    logger.info(f"   tickets_disponibles: {disponibles} tickets")
    logger.info(f"   porcentaje_ocupacion: {ocupacion:.2f}%")
    logger.info(f"   ticketera: tuboleta")
    logger.info("")
    
    # Verificaci√≥n de consistencia
    logger.info("‚úÖ VERIFICACI√ìN DE CONSISTENCIA:")
    logger.info(f"   üé´ Venta Total: {venta_total} tickets")
    logger.info(f"   üé´ Venta Diaria: {venta_diaria} tickets")
    logger.info(f"   üé´ Disponibles: {disponibles} tickets")
    logger.info(f"   üé´ Capacidad: {venta_total + disponibles} tickets")
    logger.info(f"   ‚úÖ Suma correcta: {venta_total + disponibles} = 12,025")
    logger.info("")
    
    # Resumen para ejecuci√≥n diaria
    logger.info("üîÑ RESUMEN PARA EJECUCI√ìN DIARIA (23:00):")
    logger.info("   1. ‚úÖ Login exitoso con credenciales reales")
    logger.info("   2. ‚úÖ Extracci√≥n de datos del dashboard")
    logger.info("   3. ‚úÖ C√°lculo de venta diaria (solo ventas)")
    logger.info("   4. ‚úÖ Matching con show existente")
    logger.info("   5. ‚úÖ Verificaci√≥n de consistencia")
    logger.info("   6. ‚úÖ Inserci√≥n en daily_sales")
    logger.info("")
    
    logger.info("üéâ PRUEBA FINAL COMPLETADA - LISTO PARA PRODUCCI√ìN")
    return True

def test_direct_save_simulation():
    """Simula el guardado directo en daily_sales sin guardar realmente"""
    logger.info("üß™ SIMULACI√ìN DE GUARDADO DIRECTO EN DAILY_SALES")
    logger.info("=" * 60)
    
    scraper = None
    
    try:
        # Inicializar scraper
        scraper = TuboletaScraper(headless=True)
        
        # Configurar driver
        if not scraper.setup_driver():
            logger.error("‚ùå No se pudo configurar el driver")
            return False
        
        # Login con credenciales de Josefina
        email = "josefina.perezgam@daleplay.la"
        password = "Booking5863+"
        
        logger.info(f"üîê Login con {email}")
        
        if scraper.navigate_to_login() and scraper.perform_login(email, password):
            logger.info(f"‚úÖ Login exitoso con {email}")
            
            # Navegar al dashboard
            if scraper.navigate_to_dashboard():
                logger.info("‚úÖ Navegaci√≥n al dashboard exitosa")
                
                # Extraer datos del dashboard
                events_data = scraper.extract_dashboard_data_complete()
                
                if events_data:
                    logger.info(f"‚úÖ Se extrajeron {len(events_data)} eventos del dashboard")
                    
                    # Simular procesamiento de cada evento
                    for event_data in events_data:
                        artist_name = event_data.get('artista', '')
                        venue = event_data.get('venue', '')
                        fecha_show = event_data.get('fecha_show', '')
                        
                        logger.info(f"üé≠ Procesando evento: {artist_name}")
                        logger.info(f"   Venue: {venue}")
                        logger.info(f"   Fecha: {fecha_show}")
                        
                        # Calcular totales
                        totales_show = scraper.calculate_show_totals_tuboleta(event_data)
                        
                        logger.info("üìä DATOS CALCULADOS:")
                        logger.info(f"   üìÖ Venta Diaria: {totales_show['total_today']} tickets (SOLO VENTAS)")
                        logger.info(f"   üí∞ Monto Diario: ${totales_show['ingresos_today']:,}")
                        logger.info(f"   üé´ Venta Total: {totales_show['vendido_total']} tickets")
                        logger.info(f"   üí∞ Monto Total: ${totales_show['recaudacion_total_ars']:,}")
                        logger.info(f"   üé´ Disponibles: {totales_show['disponible_total']} tickets")
                        logger.info(f"   üìä Ocupaci√≥n: {totales_show['porcentaje_ocupacion']}%")
                        
                        # Simular b√∫squeda de show existente
                        if artist_name == 'RELS B':
                            show_id = "cc2e313d-f123-491d-9094-657b803b2243"
                            logger.info(f"üîç Show encontrado: {artist_name} (ID: {show_id})")
                            
                            # Simular verificaci√≥n de registro existente
                            fecha_venta = scraper.get_current_datetime_argentina().date()
                            logger.info(f"üìÖ Verificando registro para fecha: {fecha_venta}")
                            
                            # Simular l√≥gica de guardado
                            venta_diaria = totales_show.get('total_today', 0)
                            
                            if venta_diaria == 0:
                                logger.info(f"üìä Venta diaria = 0 para {fecha_venta}")
                                logger.info("   ‚úÖ AGREGAR√çA registro con venta_diaria = 0")
                            else:
                                logger.info(f"üìä Venta diaria = {venta_diaria} tickets para {fecha_venta}")
                                logger.info("   ‚úÖ AGREGAR√çA/ACTUALIZAR√çA registro con venta diaria")
                            
                            # Mostrar registro que se insertar√≠a/actualizar√≠a
                            logger.info("üíæ REGISTRO QUE SE INSERTAR√çA/ACTUALIZAR√çA:")
                            logger.info(f"   show_id: {show_id}")
                            logger.info(f"   fecha_venta: {fecha_venta}")
                            logger.info(f"   fecha_extraccion: {scraper.get_current_datetime_argentina()}")
                            logger.info(f"   venta_diaria: {venta_diaria} tickets")
                            logger.info(f"   monto_diario_ars: ${totales_show['ingresos_today']:,}")
                            logger.info(f"   venta_total_acumulada: {totales_show['vendido_total']} tickets")
                            logger.info(f"   recaudacion_total_ars: ${totales_show['recaudacion_total_ars']:,}")
                            logger.info(f"   tickets_disponibles: {totales_show['disponible_total']} tickets")
                            logger.info(f"   porcentaje_ocupacion: {totales_show['porcentaje_ocupacion']}%")
                            logger.info(f"   ticketera: tuboleta")
                            
                            # Simular identificaci√≥n de √∫ltima extracci√≥n
                            logger.info("")
                            logger.info("üïê IDENTIFICACI√ìN DE √öLTIMA EXTRACCI√ìN:")
                            logger.info(f"   üìÖ Fecha actual: {fecha_venta}")
                            logger.info(f"   üïê Hora actual: {scraper.get_current_datetime_argentina().strftime('%H:%M:%S')}")
                            logger.info("   üîç Buscar√≠a registro existente para esta fecha")
                            logger.info("   üìä Si existe: ACTUALIZAR√çA con nuevos datos")
                            logger.info("   üìä Si no existe: CREAR√çA nuevo registro")
                            
                        logger.info("‚úÖ Evento procesado (SIMULACI√ìN - NO GUARDADO)")
                        logger.info("")
                
                else:
                    logger.warning("‚ö†Ô∏è No se pudieron extraer datos del dashboard")
            else:
                logger.error("‚ùå No se pudo navegar al dashboard")
        else:
            logger.error("‚ùå Login fallido")
        
        logger.info("üéâ SIMULACI√ìN COMPLETADA - NO SE GUARD√ì NADA")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error en simulaci√≥n: {str(e)}")
        return False
    finally:
        if scraper:
            scraper.close()

def main_direct_save():
    """Funci√≥n principal para guardar directamente en daily_sales"""
    logger.info("üöÄ INICIANDO SCRAPER TUBOLETA - GUARDADO DIRECTO EN DAILY_SALES")
    logger.info("=" * 60)
    
    scraper = None
    
    try:
        # Inicializar scraper
        scraper = TuboletaScraper(headless=True)
        
        # Configurar driver
        if not scraper.setup_driver():
            logger.error("‚ùå No se pudo configurar el driver")
            return False
        
        # Login con credenciales de Josefina
        email = "josefina.perezgam@daleplay.la"
        password = "Booking5863+"
        
        logger.info(f"üîê Login con {email}")
        
        if scraper.navigate_to_login() and scraper.perform_login(email, password):
            logger.info(f"‚úÖ Login exitoso con {email}")
            
            # Navegar al dashboard
            if scraper.navigate_to_dashboard():
                logger.info("‚úÖ Navegaci√≥n al dashboard exitosa")
                
                # Extraer datos del dashboard
                events_data = scraper.extract_dashboard_data_complete()
                
                if events_data:
                    logger.info(f"‚úÖ Se extrajeron {len(events_data)} eventos del dashboard")
                    
                    # Guardar directamente en daily_sales
                    if scraper.save_directly_to_daily_sales(events_data, email):
                        logger.info("üéâ Guardado directo en daily_sales exitoso")
                        return True
                    else:
                        logger.error("‚ùå Error en guardado directo")
                        return False
                else:
                    logger.warning("‚ö†Ô∏è No se pudieron extraer datos del dashboard")
                    return False
            else:
                logger.error("‚ùå No se pudo navegar al dashboard")
                return False
        else:
            logger.error("‚ùå Login fallido")
            return False
        
    except Exception as e:
        logger.error(f"‚ùå Error inesperado: {str(e)}")
        return False
    finally:
        if scraper:
            scraper.close()

if __name__ == "__main__":
    # Cambiar entre las funciones seg√∫n se necesite
    main_direct_save()  # Guardado directo en daily_sales
    # test_direct_save_simulation()  # Simulaci√≥n de guardado directo
    # final_test_today_sales()  # Prueba final con datos de hoy
    # test_mode_extraction()  # Modo test: scraper real sin guardar en BD
    # main()  # Modo normal: scraper real guardando en BD